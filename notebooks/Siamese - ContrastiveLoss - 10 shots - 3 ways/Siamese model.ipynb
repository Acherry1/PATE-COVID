{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3162ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34cc0b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:\n",
      "\t• TensorFlow version: 2.7.0\n",
      "\t• tf.keras version: 2.7.0\n",
      "\t• GPU device not found. Running on CPU\n"
     ]
    }
   ],
   "source": [
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "print('Using:')\n",
    "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
    "print('\\t\\u2022 tf.keras version:', tf.keras.__version__)\n",
    "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6db75f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 3 classes.\n",
      "The train set contains 30\n",
      "Found 30 images belonging to 3 classes.\n",
      "The valid set contains 30\n",
      "Found 648 images belonging to 3 classes.\n",
      "The test set contains 648\n"
     ]
    }
   ],
   "source": [
    "basedir = os.path.join(\"D:\\my_code_2\\my_code\\metacovid-siamese-neural-network-main\\metacovid-siamese-neural-network-main\\scripts\", \"dataset\", \"siamese\") \n",
    "\n",
    "train_image_list, train_y_list = utils.load_images(basedir, 'train', (100,100))\n",
    "print(\"The train set contains\",len(train_image_list)) \n",
    "\n",
    "valid_image_list, valid_y_list = utils.load_images(basedir, 'validation', (100,100))   \n",
    "print(\"The valid set contains\", len(valid_image_list))  \n",
    "\n",
    "test_image_list, test_y_list = utils.load_images(basedir, 'test', (100,100))   \n",
    "print(\"The test set contains\", len(test_image_list)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "455d52e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pairs for training 60\n",
      "number of pairs for validation 60\n",
      "number of pairs for test 1296\n"
     ]
    }
   ],
   "source": [
    "# make train pairs\n",
    "pairs_train, labels_train = utils.make_pairs(train_image_list, train_y_list)\n",
    "\n",
    "# make validation pairs\n",
    "pairs_val, labels_val = utils.make_pairs(valid_image_list, valid_y_list)\n",
    "\n",
    "# make test pairs\n",
    "pairs_test, labels_test = utils.make_pairs(test_image_list, test_y_list)\n",
    "\n",
    "x_train_1 = pairs_train[:, 0]  \n",
    "x_train_2 = pairs_train[:, 1]\n",
    "print(\"number of pairs for training\", np.shape(x_train_1)[0]) \n",
    "\n",
    "x_val_1 = pairs_val[:, 0] \n",
    "x_val_2 = pairs_val[:, 1]\n",
    "print(\"number of pairs for validation\", np.shape(x_val_1)[0]) \n",
    "\n",
    "x_test_1 = pairs_test[:, 0] \n",
    "x_test_2 = pairs_test[:, 1]\n",
    "print(\"number of pairs for test\", np.shape(x_test_1)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0ac8214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 5120)         14748995    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['sequential[0][0]',             \n",
      "                                                                  'sequential[1][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            2           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,748,997\n",
      "Trainable params: 20,482\n",
      "Non-trainable params: 14,728,515\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "SIAMESE_MODEL_FNAME = 'siamese_network.h5'\n",
    "EMBEDDING_MODEL_FNAME = 'embedding_network.h5'\n",
    "\n",
    "input_1 = Input((100,100,3))\n",
    "input_2 = Input((100,100,3))\n",
    "\n",
    "embedding_network = tf.keras.models.load_model(\"D:\\my_code_2\\my_code\\metacovid-siamese-neural-network-main\\metacovid-siamese-neural-network-main\\scripts\\embedding_network.h5\")\n",
    "embedding_network.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential() \n",
    "for layer in embedding_network.layers:  \n",
    "    model.add(layer) \n",
    "\n",
    "model.add(Flatten(name='flat'))\n",
    "model.add(Dense(5120, name='den', activation='sigmoid', kernel_regularizer='l2')) \n",
    " \n",
    "output_1 = model(input_1) \n",
    "output_2 = model(input_2) \n",
    " \n",
    "merge_layer = Lambda(utils.manhattan_distance)([output_1, output_2]) \n",
    "output_layer = Dense(1, activation=\"sigmoid\")(merge_layer) \n",
    "siamese = Model(inputs=[input_1, input_2], outputs=output_layer) \n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea72350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" callbacks \"\"\"\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, min_delta=0.0001)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='siamese_network.h5', verbose=1, \n",
    "                                save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bbba899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 5120)         14748995    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['sequential[0][0]',             \n",
      "                                                                  'sequential[1][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            2           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,748,997\n",
      "Trainable params: 20,482\n",
      "Non-trainable params: 14,728,515\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3639 - accuracy: 0.5500\n",
      "Epoch 00001: val_loss improved from inf to 0.32494, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 13s 200ms/step - loss: 0.3639 - accuracy: 0.5500 - val_loss: 0.3249 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
      "Epoch 2/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.3200 - accuracy: 0.5500\n",
      "Epoch 00002: val_loss improved from 0.32494 to 0.28012, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 12s 197ms/step - loss: 0.3200 - accuracy: 0.5500 - val_loss: 0.2801 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
      "Epoch 3/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2691 - accuracy: 0.5500\n",
      "Epoch 00003: val_loss improved from 0.28012 to 0.23098, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 12s 198ms/step - loss: 0.2691 - accuracy: 0.5500 - val_loss: 0.2310 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
      "Epoch 4/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.5500\n",
      "Epoch 00004: val_loss improved from 0.23098 to 0.19233, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 189ms/step - loss: 0.2174 - accuracy: 0.5500 - val_loss: 0.1923 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
      "Epoch 5/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1849 - accuracy: 0.5667 ETA: \n",
      "Epoch 00005: val_loss improved from 0.19233 to 0.17688, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 189ms/step - loss: 0.1849 - accuracy: 0.5667 - val_loss: 0.1769 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
      "Epoch 6/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.5667\n",
      "Epoch 00006: val_loss improved from 0.17688 to 0.16566, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1733 - accuracy: 0.5667 - val_loss: 0.1657 - val_accuracy: 0.6833 - lr: 1.0000e-04\n",
      "Epoch 7/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1678 - accuracy: 0.5833\n",
      "Epoch 00007: val_loss improved from 0.16566 to 0.16283, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.1678 - accuracy: 0.5833 - val_loss: 0.1628 - val_accuracy: 0.6500 - lr: 1.0000e-04\n",
      "Epoch 8/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.5833\n",
      "Epoch 00008: val_loss improved from 0.16283 to 0.15720, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1659 - accuracy: 0.5833 - val_loss: 0.1572 - val_accuracy: 0.7167 - lr: 1.0000e-04\n",
      "Epoch 9/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.5833\n",
      "Epoch 00009: val_loss improved from 0.15720 to 0.15481, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1609 - accuracy: 0.5833 - val_loss: 0.1548 - val_accuracy: 0.7167 - lr: 1.0000e-04\n",
      "Epoch 10/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.6167\n",
      "Epoch 00010: val_loss did not improve from 0.15481\n",
      "60/60 [==============================] - 11s 183ms/step - loss: 0.1626 - accuracy: 0.6167 - val_loss: 0.1549 - val_accuracy: 0.7167 - lr: 1.0000e-04\n",
      "Epoch 11/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1603 - accuracy: 0.6333\n",
      "Epoch 00011: val_loss improved from 0.15481 to 0.15317, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 193ms/step - loss: 0.1603 - accuracy: 0.6333 - val_loss: 0.1532 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
      "Epoch 12/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.6500\n",
      "Epoch 00012: val_loss improved from 0.15317 to 0.15151, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1591 - accuracy: 0.6500 - val_loss: 0.1515 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
      "Epoch 13/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1566 - accuracy: 0.6500\n",
      "Epoch 00013: val_loss did not improve from 0.15151\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1566 - accuracy: 0.6500 - val_loss: 0.1536 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 14/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.6500\n",
      "Epoch 00014: val_loss did not improve from 0.15151\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1539 - accuracy: 0.6500 - val_loss: 0.1526 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
      "Epoch 15/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1558 - accuracy: 0.6333\n",
      "Epoch 00015: val_loss did not improve from 0.15151\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1558 - accuracy: 0.6333 - val_loss: 0.1536 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 16/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1573 - accuracy: 0.6833\n",
      "Epoch 00016: val_loss improved from 0.15151 to 0.14879, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 189ms/step - loss: 0.1573 - accuracy: 0.6833 - val_loss: 0.1488 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 17/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.7000\n",
      "Epoch 00017: val_loss improved from 0.14879 to 0.14755, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1548 - accuracy: 0.7000 - val_loss: 0.1476 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
      "Epoch 18/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.6667\n",
      "Epoch 00018: val_loss did not improve from 0.14755\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1563 - accuracy: 0.6667 - val_loss: 0.1488 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 19/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1520 - accuracy: 0.7000\n",
      "Epoch 00019: val_loss did not improve from 0.14755\n",
      "60/60 [==============================] - 12s 201ms/step - loss: 0.1520 - accuracy: 0.7000 - val_loss: 0.1477 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
      "Epoch 20/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.7167\n",
      "Epoch 00020: val_loss improved from 0.14755 to 0.14587, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 184ms/step - loss: 0.1535 - accuracy: 0.7167 - val_loss: 0.1459 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
      "Epoch 21/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.6833\n",
      "Epoch 00021: val_loss did not improve from 0.14587\n",
      "60/60 [==============================] - 11s 190ms/step - loss: 0.1508 - accuracy: 0.6833 - val_loss: 0.1467 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 22/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1530 - accuracy: 0.7167\n",
      "Epoch 00022: val_loss improved from 0.14587 to 0.14376, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 12s 197ms/step - loss: 0.1530 - accuracy: 0.7167 - val_loss: 0.1438 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
      "Epoch 23/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.7333\n",
      "Epoch 00023: val_loss did not improve from 0.14376\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1498 - accuracy: 0.7333 - val_loss: 0.1453 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 24/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.7667 ETA: 0s - loss: 0.1556 - ac\n",
      "Epoch 00024: val_loss improved from 0.14376 to 0.14207, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 191ms/step - loss: 0.1485 - accuracy: 0.7667 - val_loss: 0.1421 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 25/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.7500\n",
      "Epoch 00025: val_loss did not improve from 0.14207\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1485 - accuracy: 0.7500 - val_loss: 0.1426 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 26/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.7000\n",
      "Epoch 00026: val_loss improved from 0.14207 to 0.14139, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 192ms/step - loss: 0.1505 - accuracy: 0.7000 - val_loss: 0.1414 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 27/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1468 - accuracy: 0.7667\n",
      "Epoch 00027: val_loss did not improve from 0.14139\n",
      "60/60 [==============================] - 12s 209ms/step - loss: 0.1468 - accuracy: 0.7667 - val_loss: 0.1415 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 28/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1492 - accuracy: 0.7667\n",
      "Epoch 00028: val_loss improved from 0.14139 to 0.14054, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 191ms/step - loss: 0.1492 - accuracy: 0.7667 - val_loss: 0.1405 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 29/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.7500\n",
      "Epoch 00029: val_loss improved from 0.14054 to 0.13947, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 189ms/step - loss: 0.1472 - accuracy: 0.7500 - val_loss: 0.1395 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 30/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1459 - accuracy: 0.8167\n",
      "Epoch 00030: val_loss did not improve from 0.13947\n",
      "60/60 [==============================] - 11s 183ms/step - loss: 0.1459 - accuracy: 0.8167 - val_loss: 0.1395 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 31/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1453 - accuracy: 0.7667\n",
      "Epoch 00031: val_loss improved from 0.13947 to 0.13841, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 192ms/step - loss: 0.1453 - accuracy: 0.7667 - val_loss: 0.1384 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
      "Epoch 32/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.8000\n",
      "Epoch 00032: val_loss improved from 0.13841 to 0.13774, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 191ms/step - loss: 0.1452 - accuracy: 0.8000 - val_loss: 0.1377 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 33/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1454 - accuracy: 0.8167\n",
      "Epoch 00033: val_loss did not improve from 0.13774\n",
      "60/60 [==============================] - 11s 193ms/step - loss: 0.1454 - accuracy: 0.8167 - val_loss: 0.1399 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 34/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.8167 E\n",
      "Epoch 00034: val_loss improved from 0.13774 to 0.13644, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 192ms/step - loss: 0.1438 - accuracy: 0.8167 - val_loss: 0.1364 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 35/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1455 - accuracy: 0.8000\n",
      "Epoch 00035: val_loss improved from 0.13644 to 0.13563, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1455 - accuracy: 0.8000 - val_loss: 0.1356 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 36/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1437 - accuracy: 0.8333\n",
      "Epoch 00036: val_loss did not improve from 0.13563\n",
      "60/60 [==============================] - 11s 182ms/step - loss: 0.1437 - accuracy: 0.8333 - val_loss: 0.1359 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
      "Epoch 37/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.8333\n",
      "Epoch 00037: val_loss did not improve from 0.13563\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1421 - accuracy: 0.8333 - val_loss: 0.1368 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
      "Epoch 38/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.7833\n",
      "Epoch 00038: val_loss did not improve from 0.13563\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1451 - accuracy: 0.7833 - val_loss: 0.1386 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 39/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.8167\n",
      "Epoch 00039: val_loss improved from 0.13563 to 0.13526, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 12s 196ms/step - loss: 0.1430 - accuracy: 0.8167 - val_loss: 0.1353 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 40/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.8167\n",
      "Epoch 00040: val_loss did not improve from 0.13526\n",
      "60/60 [==============================] - 11s 192ms/step - loss: 0.1433 - accuracy: 0.8167 - val_loss: 0.1354 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
      "Epoch 41/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.8167\n",
      "Epoch 00041: val_loss improved from 0.13526 to 0.13248, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1395 - accuracy: 0.8167 - val_loss: 0.1325 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 42/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1476 - accuracy: 0.8000\n",
      "Epoch 00042: val_loss did not improve from 0.13248\n",
      "60/60 [==============================] - 11s 192ms/step - loss: 0.1476 - accuracy: 0.8000 - val_loss: 0.1327 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 43/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1360 - accuracy: 0.8000\n",
      "Epoch 00043: val_loss did not improve from 0.13248\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1360 - accuracy: 0.8000 - val_loss: 0.1409 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 44/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.8833\n",
      "Epoch 00044: val_loss improved from 0.13248 to 0.13078, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 190ms/step - loss: 0.1393 - accuracy: 0.8833 - val_loss: 0.1308 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 45/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.8667\n",
      "Epoch 00045: val_loss improved from 0.13078 to 0.13057, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 191ms/step - loss: 0.1390 - accuracy: 0.8667 - val_loss: 0.1306 - val_accuracy: 0.8167 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1378 - accuracy: 0.8000\n",
      "Epoch 00046: val_loss did not improve from 0.13057\n",
      "60/60 [==============================] - 11s 191ms/step - loss: 0.1378 - accuracy: 0.8000 - val_loss: 0.1315 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 47/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1380 - accuracy: 0.8667\n",
      "Epoch 00047: val_loss improved from 0.13057 to 0.12957, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1380 - accuracy: 0.8667 - val_loss: 0.1296 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 48/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.8833\n",
      "Epoch 00048: val_loss did not improve from 0.12957\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.1358 - accuracy: 0.8833 - val_loss: 0.1303 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
      "Epoch 49/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.8167\n",
      "Epoch 00049: val_loss improved from 0.12957 to 0.12926, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1395 - accuracy: 0.8167 - val_loss: 0.1293 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 50/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.8667\n",
      "Epoch 00050: val_loss improved from 0.12926 to 0.12786, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1371 - accuracy: 0.8667 - val_loss: 0.1279 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 51/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.8833\n",
      "Epoch 00051: val_loss did not improve from 0.12786\n",
      "60/60 [==============================] - 11s 191ms/step - loss: 0.1348 - accuracy: 0.8833 - val_loss: 0.1286 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
      "Epoch 52/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.8667\n",
      "Epoch 00052: val_loss improved from 0.12786 to 0.12686, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 192ms/step - loss: 0.1344 - accuracy: 0.8667 - val_loss: 0.1269 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 53/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.8833\n",
      "Epoch 00053: val_loss did not improve from 0.12686\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1331 - accuracy: 0.8833 - val_loss: 0.1301 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 54/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.8833\n",
      "Epoch 00054: val_loss improved from 0.12686 to 0.12608, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 12s 196ms/step - loss: 0.1373 - accuracy: 0.8833 - val_loss: 0.1261 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 55/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.8667\n",
      "Epoch 00055: val_loss did not improve from 0.12608\n",
      "60/60 [==============================] - 12s 196ms/step - loss: 0.1329 - accuracy: 0.8667 - val_loss: 0.1262 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 56/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.8833\n",
      "Epoch 00056: val_loss improved from 0.12608 to 0.12531, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 192ms/step - loss: 0.1335 - accuracy: 0.8833 - val_loss: 0.1253 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 57/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1324 - accuracy: 0.8833\n",
      "Epoch 00057: val_loss improved from 0.12531 to 0.12529, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 189ms/step - loss: 0.1324 - accuracy: 0.8833 - val_loss: 0.1253 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 58/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.8833\n",
      "Epoch 00058: val_loss improved from 0.12529 to 0.12424, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 192ms/step - loss: 0.1321 - accuracy: 0.8833 - val_loss: 0.1242 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 59/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1306 - accuracy: 0.8833\n",
      "Epoch 00059: val_loss improved from 0.12424 to 0.12363, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 12s 197ms/step - loss: 0.1306 - accuracy: 0.8833 - val_loss: 0.1236 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
      "Epoch 60/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1307 - accuracy: 0.8833\n",
      "Epoch 00060: val_loss did not improve from 0.12363\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.1307 - accuracy: 0.8833 - val_loss: 0.1245 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
      "Epoch 61/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1308 - accuracy: 0.8833\n",
      "Epoch 00061: val_loss improved from 0.12363 to 0.12229, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 183ms/step - loss: 0.1308 - accuracy: 0.8833 - val_loss: 0.1223 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 62/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.8833\n",
      "Epoch 00062: val_loss did not improve from 0.12229\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1298 - accuracy: 0.8833 - val_loss: 0.1238 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 63/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1322 - accuracy: 0.8833\n",
      "Epoch 00063: val_loss did not improve from 0.12229\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1322 - accuracy: 0.8833 - val_loss: 0.1238 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 64/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.8500\n",
      "Epoch 00064: val_loss improved from 0.12229 to 0.12139, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1331 - accuracy: 0.8500 - val_loss: 0.1214 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 65/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.8833\n",
      "Epoch 00065: val_loss improved from 0.12139 to 0.12100, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1280 - accuracy: 0.8833 - val_loss: 0.1210 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 66/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1273 - accuracy: 0.8833\n",
      "Epoch 00066: val_loss improved from 0.12100 to 0.12054, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1273 - accuracy: 0.8833 - val_loss: 0.1205 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 67/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.9000\n",
      "Epoch 00067: val_loss did not improve from 0.12054\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1296 - accuracy: 0.9000 - val_loss: 0.1209 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 68/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 0.8833\n",
      "Epoch 00068: val_loss did not improve from 0.12054\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1279 - accuracy: 0.8833 - val_loss: 0.1214 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 69/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1286 - accuracy: 0.8833\n",
      "Epoch 00069: val_loss did not improve from 0.12054\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1286 - accuracy: 0.8833 - val_loss: 0.1214 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 70/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.8667\n",
      "Epoch 00070: val_loss improved from 0.12054 to 0.11868, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1275 - accuracy: 0.8667 - val_loss: 0.1187 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
      "Epoch 71/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.8833\n",
      "Epoch 00071: val_loss did not improve from 0.11868\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1247 - accuracy: 0.8833 - val_loss: 0.1196 - val_accuracy: 0.9333 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.8833\n",
      "Epoch 00072: val_loss did not improve from 0.11868\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1284 - accuracy: 0.8833 - val_loss: 0.1258 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
      "Epoch 73/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.8500\n",
      "Epoch 00073: val_loss did not improve from 0.11868\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1295 - accuracy: 0.8500 - val_loss: 0.1193 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 74/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1248 - accuracy: 0.9000\n",
      "Epoch 00074: val_loss improved from 0.11868 to 0.11867, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 184ms/step - loss: 0.1248 - accuracy: 0.9000 - val_loss: 0.1187 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 75/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1245 - accuracy: 0.8833\n",
      "Epoch 00075: val_loss improved from 0.11867 to 0.11760, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 189ms/step - loss: 0.1245 - accuracy: 0.8833 - val_loss: 0.1176 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 76/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1254 - accuracy: 0.8833\n",
      "Epoch 00076: val_loss did not improve from 0.11760\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1254 - accuracy: 0.8833 - val_loss: 0.1193 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 77/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.8833\n",
      "Epoch 00077: val_loss did not improve from 0.11760\n",
      "60/60 [==============================] - 11s 189ms/step - loss: 0.1265 - accuracy: 0.8833 - val_loss: 0.1186 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 78/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.9333\n",
      "Epoch 00078: val_loss did not improve from 0.11760\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.1219 - accuracy: 0.9333 - val_loss: 0.1178 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 79/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1242 - accuracy: 0.8833\n",
      "Epoch 00079: val_loss improved from 0.11760 to 0.11537, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1242 - accuracy: 0.8833 - val_loss: 0.1154 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 80/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.9000\n",
      "Epoch 00080: val_loss did not improve from 0.11537\n",
      "60/60 [==============================] - 11s 190ms/step - loss: 0.1262 - accuracy: 0.9000 - val_loss: 0.1164 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 81/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 0.8833\n",
      "Epoch 00081: val_loss improved from 0.11537 to 0.11528, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1232 - accuracy: 0.8833 - val_loss: 0.1153 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 82/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.9000\n",
      "Epoch 00082: val_loss did not improve from 0.11528\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.1234 - accuracy: 0.9000 - val_loss: 0.1187 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 83/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.8833\n",
      "Epoch 00083: val_loss improved from 0.11528 to 0.11358, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 191ms/step - loss: 0.1229 - accuracy: 0.8833 - val_loss: 0.1136 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 84/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.9000\n",
      "Epoch 00084: val_loss improved from 0.11358 to 0.11300, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1209 - accuracy: 0.9000 - val_loss: 0.1130 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 85/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.8833\n",
      "Epoch 00085: val_loss improved from 0.11300 to 0.11251, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1228 - accuracy: 0.8833 - val_loss: 0.1125 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 86/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.8833\n",
      "Epoch 00086: val_loss did not improve from 0.11251\n",
      "60/60 [==============================] - 11s 190ms/step - loss: 0.1199 - accuracy: 0.8833 - val_loss: 0.1126 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 87/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.8833\n",
      "Epoch 00087: val_loss did not improve from 0.11251\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1192 - accuracy: 0.8833 - val_loss: 0.1139 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 88/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9500\n",
      "Epoch 00088: val_loss did not improve from 0.11251\n",
      "60/60 [==============================] - 11s 190ms/step - loss: 0.1187 - accuracy: 0.9500 - val_loss: 0.1133 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
      "Epoch 89/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.8833\n",
      "Epoch 00089: val_loss improved from 0.11251 to 0.11165, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1190 - accuracy: 0.8833 - val_loss: 0.1117 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 90/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 0.9167\n",
      "Epoch 00090: val_loss did not improve from 0.11165\n",
      "60/60 [==============================] - 11s 178ms/step - loss: 0.1185 - accuracy: 0.9167 - val_loss: 0.1122 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 91/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.9000\n",
      "Epoch 00091: val_loss did not improve from 0.11165\n",
      "60/60 [==============================] - 11s 180ms/step - loss: 0.1192 - accuracy: 0.9000 - val_loss: 0.1129 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 92/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.8833\n",
      "Epoch 00092: val_loss improved from 0.11165 to 0.11085, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 180ms/step - loss: 0.1190 - accuracy: 0.8833 - val_loss: 0.1109 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 93/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.8833\n",
      "Epoch 00093: val_loss improved from 0.11085 to 0.11025, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1222 - accuracy: 0.8833 - val_loss: 0.1103 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
      "Epoch 94/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.9000\n",
      "Epoch 00094: val_loss improved from 0.11025 to 0.11018, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.1196 - accuracy: 0.9000 - val_loss: 0.1102 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 95/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9000\n",
      "Epoch 00095: val_loss did not improve from 0.11018\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.1169 - accuracy: 0.9000 - val_loss: 0.1126 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 96/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9167\n",
      "Epoch 00096: val_loss improved from 0.11018 to 0.10840, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 192ms/step - loss: 0.1172 - accuracy: 0.9167 - val_loss: 0.1084 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 97/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9167\n",
      "Epoch 00097: val_loss did not improve from 0.10840\n",
      "60/60 [==============================] - 12s 195ms/step - loss: 0.1156 - accuracy: 0.9167 - val_loss: 0.1135 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 98/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9000\n",
      "Epoch 00098: val_loss did not improve from 0.10840\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1178 - accuracy: 0.9000 - val_loss: 0.1086 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 99/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.9500\n",
      "Epoch 00099: val_loss improved from 0.10840 to 0.10763, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1154 - accuracy: 0.9500 - val_loss: 0.1076 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 100/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.8833\n",
      "Epoch 00100: val_loss improved from 0.10763 to 0.10733, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1151 - accuracy: 0.8833 - val_loss: 0.1073 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 101/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9000\n",
      "Epoch 00101: val_loss did not improve from 0.10733\n",
      "60/60 [==============================] - 11s 183ms/step - loss: 0.1143 - accuracy: 0.9000 - val_loss: 0.1086 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 102/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9667\n",
      "Epoch 00102: val_loss improved from 0.10733 to 0.10711, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 190ms/step - loss: 0.1146 - accuracy: 0.9667 - val_loss: 0.1071 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 103/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9000\n",
      "Epoch 00103: val_loss improved from 0.10711 to 0.10571, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1138 - accuracy: 0.9000 - val_loss: 0.1057 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 104/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9167\n",
      "Epoch 00104: val_loss improved from 0.10571 to 0.10522, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 191ms/step - loss: 0.1132 - accuracy: 0.9167 - val_loss: 0.1052 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 105/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9167\n",
      "Epoch 00105: val_loss did not improve from 0.10522\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1133 - accuracy: 0.9167 - val_loss: 0.1064 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 106/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9333\n",
      "Epoch 00106: val_loss did not improve from 0.10522\n",
      "60/60 [==============================] - 11s 184ms/step - loss: 0.1127 - accuracy: 0.9333 - val_loss: 0.1062 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 107/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9333\n",
      "Epoch 00107: val_loss did not improve from 0.10522\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1139 - accuracy: 0.9333 - val_loss: 0.1056 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 108/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9667\n",
      "Epoch 00108: val_loss improved from 0.10522 to 0.10427, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1138 - accuracy: 0.9667 - val_loss: 0.1043 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 109/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9833\n",
      "Epoch 00109: val_loss did not improve from 0.10427\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1108 - accuracy: 0.9833 - val_loss: 0.1055 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
      "Epoch 110/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9000\n",
      "Epoch 00110: val_loss did not improve from 0.10427\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1132 - accuracy: 0.9000 - val_loss: 0.1054 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 111/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9167\n",
      "Epoch 00111: val_loss improved from 0.10427 to 0.10338, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 191ms/step - loss: 0.1170 - accuracy: 0.9167 - val_loss: 0.1034 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 112/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.9333\n",
      "Epoch 00112: val_loss did not improve from 0.10338\n",
      "60/60 [==============================] - 11s 184ms/step - loss: 0.1112 - accuracy: 0.9333 - val_loss: 0.1037 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 113/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9167\n",
      "Epoch 00113: val_loss improved from 0.10338 to 0.10271, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 191ms/step - loss: 0.1108 - accuracy: 0.9167 - val_loss: 0.1027 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 114/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.9500\n",
      "Epoch 00114: val_loss improved from 0.10271 to 0.10168, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1115 - accuracy: 0.9500 - val_loss: 0.1017 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 115/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.9167\n",
      "Epoch 00115: val_loss did not improve from 0.10168\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1117 - accuracy: 0.9167 - val_loss: 0.1047 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 116/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.9167\n",
      "Epoch 00116: val_loss improved from 0.10168 to 0.10163, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1106 - accuracy: 0.9167 - val_loss: 0.1016 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 117/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9333\n",
      "Epoch 00117: val_loss did not improve from 0.10163\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.1094 - accuracy: 0.9333 - val_loss: 0.1023 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 118/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9333\n",
      "Epoch 00118: val_loss did not improve from 0.10163\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1121 - accuracy: 0.9333 - val_loss: 0.1022 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 119/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1122 - accuracy: 0.9167\n",
      "Epoch 00119: val_loss improved from 0.10163 to 0.10067, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1122 - accuracy: 0.9167 - val_loss: 0.1007 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 120/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.9000\n",
      "Epoch 00120: val_loss improved from 0.10067 to 0.09984, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 12s 194ms/step - loss: 0.1112 - accuracy: 0.9000 - val_loss: 0.0998 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 121/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9000\n",
      "Epoch 00121: val_loss did not improve from 0.09984\n",
      "60/60 [==============================] - 11s 191ms/step - loss: 0.1108 - accuracy: 0.9000 - val_loss: 0.1005 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 122/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9500\n",
      "Epoch 00122: val_loss did not improve from 0.09984\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.1086 - accuracy: 0.9500 - val_loss: 0.1037 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 123/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1144 - accuracy: 0.9500\n",
      "Epoch 00123: val_loss did not improve from 0.09984\n",
      "60/60 [==============================] - 11s 183ms/step - loss: 0.1144 - accuracy: 0.9500 - val_loss: 0.1020 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
      "Epoch 124/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.9167\n",
      "Epoch 00124: val_loss did not improve from 0.09984\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.1103 - accuracy: 0.9167 - val_loss: 0.1005 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 125/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.9333\n",
      "Epoch 00125: val_loss improved from 0.09984 to 0.09946, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1058 - accuracy: 0.9333 - val_loss: 0.0995 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 126/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.9667\n",
      "Epoch 00126: val_loss did not improve from 0.09946\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.1076 - accuracy: 0.9667 - val_loss: 0.1012 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 127/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9333\n",
      "Epoch 00127: val_loss improved from 0.09946 to 0.09783, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1054 - accuracy: 0.9333 - val_loss: 0.0978 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 128/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9667\n",
      "Epoch 00128: val_loss improved from 0.09783 to 0.09711, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.1072 - accuracy: 0.9667 - val_loss: 0.0971 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 129/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 0.9500\n",
      "Epoch 00129: val_loss did not improve from 0.09711\n",
      "60/60 [==============================] - 11s 182ms/step - loss: 0.1055 - accuracy: 0.9500 - val_loss: 0.0980 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 130/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1047 - accuracy: 0.9667\n",
      "Epoch 00130: val_loss improved from 0.09711 to 0.09648, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 189ms/step - loss: 0.1047 - accuracy: 0.9667 - val_loss: 0.0965 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 131/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9667 ETA: 0s - loss: 0.1071 - accuracy\n",
      "Epoch 00131: val_loss did not improve from 0.09648\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1054 - accuracy: 0.9667 - val_loss: 0.1001 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 132/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.9333\n",
      "Epoch 00132: val_loss did not improve from 0.09648\n",
      "60/60 [==============================] - 11s 184ms/step - loss: 0.1046 - accuracy: 0.9333 - val_loss: 0.0970 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 133/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.9833\n",
      "Epoch 00133: val_loss did not improve from 0.09648\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1039 - accuracy: 0.9833 - val_loss: 0.0972 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 134/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9167\n",
      "Epoch 00134: val_loss did not improve from 0.09648\n",
      "60/60 [==============================] - 11s 181ms/step - loss: 0.1074 - accuracy: 0.9167 - val_loss: 0.0973 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
      "Epoch 135/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.9500\n",
      "Epoch 00135: val_loss improved from 0.09648 to 0.09461, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.1039 - accuracy: 0.9500 - val_loss: 0.0946 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 136/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9500\n",
      "Epoch 00136: val_loss did not improve from 0.09461\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1036 - accuracy: 0.9500 - val_loss: 0.0965 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 137/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9333\n",
      "Epoch 00137: val_loss did not improve from 0.09461\n",
      "60/60 [==============================] - 11s 182ms/step - loss: 0.1036 - accuracy: 0.9333 - val_loss: 0.0948 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 138/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9667\n",
      "Epoch 00138: val_loss improved from 0.09461 to 0.09379, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.1028 - accuracy: 0.9667 - val_loss: 0.0938 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 139/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9500\n",
      "Epoch 00139: val_loss did not improve from 0.09379\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.1033 - accuracy: 0.9500 - val_loss: 0.0947 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 140/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9667\n",
      "Epoch 00140: val_loss did not improve from 0.09379\n",
      "60/60 [==============================] - 11s 184ms/step - loss: 0.1016 - accuracy: 0.9667 - val_loss: 0.0954 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 141/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9667\n",
      "Epoch 00141: val_loss improved from 0.09379 to 0.09272, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 190ms/step - loss: 0.1032 - accuracy: 0.9667 - val_loss: 0.0927 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 142/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9667\n",
      "Epoch 00142: val_loss did not improve from 0.09272\n",
      "60/60 [==============================] - 11s 189ms/step - loss: 0.1018 - accuracy: 0.9667 - val_loss: 0.0937 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 143/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9167\n",
      "Epoch 00143: val_loss did not improve from 0.09272\n",
      "60/60 [==============================] - 11s 183ms/step - loss: 0.1030 - accuracy: 0.9167 - val_loss: 0.1002 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 144/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9167\n",
      "Epoch 00144: val_loss improved from 0.09272 to 0.09227, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 182ms/step - loss: 0.1037 - accuracy: 0.9167 - val_loss: 0.0923 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 145/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0997 - accuracy: 0.9667\n",
      "Epoch 00145: val_loss did not improve from 0.09227\n",
      "60/60 [==============================] - 11s 179ms/step - loss: 0.0997 - accuracy: 0.9667 - val_loss: 0.0942 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 146/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9500\n",
      "Epoch 00146: val_loss improved from 0.09227 to 0.09189, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 183ms/step - loss: 0.1018 - accuracy: 0.9500 - val_loss: 0.0919 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 147/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.9500\n",
      "Epoch 00147: val_loss improved from 0.09189 to 0.09078, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.1017 - accuracy: 0.9500 - val_loss: 0.0908 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 148/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.9667\n",
      "Epoch 00148: val_loss did not improve from 0.09078\n",
      "60/60 [==============================] - 11s 183ms/step - loss: 0.0994 - accuracy: 0.9667 - val_loss: 0.0913 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 149/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9833\n",
      "Epoch 00149: val_loss did not improve from 0.09078\n",
      "60/60 [==============================] - 11s 184ms/step - loss: 0.0988 - accuracy: 0.9833 - val_loss: 0.0914 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 150/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9833\n",
      "Epoch 00150: val_loss did not improve from 0.09078\n",
      "60/60 [==============================] - 11s 184ms/step - loss: 0.0988 - accuracy: 0.9833 - val_loss: 0.0912 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 151/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.9500\n",
      "Epoch 00151: val_loss did not improve from 0.09078\n",
      "60/60 [==============================] - 11s 184ms/step - loss: 0.0995 - accuracy: 0.9500 - val_loss: 0.0912 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 152/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9833\n",
      "Epoch 00152: val_loss improved from 0.09078 to 0.09010, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.0986 - accuracy: 0.9833 - val_loss: 0.0901 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 153/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9667\n",
      "Epoch 00153: val_loss improved from 0.09010 to 0.08957, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 191ms/step - loss: 0.0972 - accuracy: 0.9667 - val_loss: 0.0896 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 154/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9667\n",
      "Epoch 00154: val_loss did not improve from 0.08957\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.0966 - accuracy: 0.9667 - val_loss: 0.0913 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 155/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9667\n",
      "Epoch 00155: val_loss did not improve from 0.08957\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.0969 - accuracy: 0.9667 - val_loss: 0.0901 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 156/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9667\n",
      "Epoch 00156: val_loss did not improve from 0.08957\n",
      "60/60 [==============================] - 11s 182ms/step - loss: 0.0965 - accuracy: 0.9667 - val_loss: 0.0918 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 157/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.9833\n",
      "Epoch 00157: val_loss improved from 0.08957 to 0.08780, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 186ms/step - loss: 0.0967 - accuracy: 0.9833 - val_loss: 0.0878 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 158/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9833\n",
      "Epoch 00158: val_loss did not improve from 0.08780\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.0949 - accuracy: 0.9833 - val_loss: 0.0910 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 159/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9833\n",
      "Epoch 00159: val_loss improved from 0.08780 to 0.08725, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 192ms/step - loss: 0.0962 - accuracy: 0.9833 - val_loss: 0.0872 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 160/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.9500\n",
      "Epoch 00160: val_loss did not improve from 0.08725\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.0959 - accuracy: 0.9500 - val_loss: 0.0876 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 161/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 0.9667\n",
      "Epoch 00161: val_loss improved from 0.08725 to 0.08646, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 189ms/step - loss: 0.0959 - accuracy: 0.9667 - val_loss: 0.0865 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 162/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9500\n",
      "Epoch 00162: val_loss did not improve from 0.08646\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.0965 - accuracy: 0.9500 - val_loss: 0.0874 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 163/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9833\n",
      "Epoch 00163: val_loss did not improve from 0.08646\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.0946 - accuracy: 0.9833 - val_loss: 0.0865 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 164/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9833\n",
      "Epoch 00164: val_loss did not improve from 0.08646\n",
      "60/60 [==============================] - 11s 189ms/step - loss: 0.0954 - accuracy: 0.9833 - val_loss: 0.0865 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 165/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9333\n",
      "Epoch 00165: val_loss did not improve from 0.08646\n",
      "60/60 [==============================] - 11s 184ms/step - loss: 0.0945 - accuracy: 0.9333 - val_loss: 0.0921 - val_accuracy: 0.9833 - lr: 1.0000e-04\n",
      "Epoch 166/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.9833\n",
      "Epoch 00166: val_loss improved from 0.08646 to 0.08504, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.0942 - accuracy: 0.9833 - val_loss: 0.0850 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 167/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9833\n",
      "Epoch 00167: val_loss did not improve from 0.08504\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.0939 - accuracy: 0.9833 - val_loss: 0.0870 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 168/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.9833 ETA: 1s - l\n",
      "Epoch 00168: val_loss did not improve from 0.08504\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.0930 - accuracy: 0.9833 - val_loss: 0.0853 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 169/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9833\n",
      "Epoch 00169: val_loss did not improve from 0.08504\n",
      "60/60 [==============================] - 11s 185ms/step - loss: 0.0920 - accuracy: 0.9833 - val_loss: 0.0854 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 170/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9667 ETA: 0s - loss: 0.0878 - accuracy\n",
      "Epoch 00170: val_loss did not improve from 0.08504\n",
      "60/60 [==============================] - 11s 184ms/step - loss: 0.0946 - accuracy: 0.9667 - val_loss: 0.0857 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 171/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9667\n",
      "Epoch 00171: val_loss improved from 0.08504 to 0.08460, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 187ms/step - loss: 0.0928 - accuracy: 0.9667 - val_loss: 0.0846 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 172/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9833\n",
      "Epoch 00172: val_loss improved from 0.08460 to 0.08320, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.0943 - accuracy: 0.9833 - val_loss: 0.0832 - val_accuracy: 0.9667 - lr: 1.0000e-04\n",
      "Epoch 173/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.9833\n",
      "Epoch 00173: val_loss did not improve from 0.08320\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.0916 - accuracy: 0.9833 - val_loss: 0.0837 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 174/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9667\n",
      "Epoch 00174: val_loss improved from 0.08320 to 0.08274, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.0938 - accuracy: 0.9667 - val_loss: 0.0827 - val_accuracy: 0.9833 - lr: 1.0000e-04\n",
      "Epoch 175/175\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9833\n",
      "Epoch 00175: val_loss did not improve from 0.08274\n",
      "60/60 [==============================] - 11s 188ms/step - loss: 0.0914 - accuracy: 0.9833 - val_loss: 0.0841 - val_accuracy: 0.9833 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "\"\"\" train the model \"\"\"\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "siamese.compile(loss=utils.loss(1), optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "# siamese.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "siamese.summary()\n",
    "history = siamese.fit([x_train_1, x_train_2],\n",
    "    labels_train,\n",
    "    validation_data=([x_val_1, x_val_2], labels_val),\n",
    "    batch_size=1,\n",
    "    epochs=175,   # 175 for contrastive 100 for cross ent\n",
    "    callbacks = [checkpointer, early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "908681b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "utils.plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f0998a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the constrastive loss\n",
    "utils.plt_metric(history=history.history, metric=\"loss\", title=\"Constrastive Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80bcc99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 94s 2s/step - loss: 0.0999 - accuracy: 0.9336\n",
      "test loss, test acc: [0.09994036704301834, 0.9336419701576233]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Test the model \"\"\"\n",
    "results = siamese.evaluate([x_test_1, x_test_2], labels_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29c415eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6482859 , 0.1813162 , 0.6389365 , ..., 0.18665549, 0.649411  ,\n",
       "       0.03620934], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = siamese.predict([x_test_1, x_test_2]).squeeze()\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "456693ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ..., False,  True, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_pred = Y_pred > .5\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "684afb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = labels_test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1a1e58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate on test data\n",
      "Accuracy: 0.933641975308642\n",
      "Precision: 0.9393718571139016\n",
      "Recall: 0.933641975308642\n",
      "ROC AUC: 0.9336419753086419\n",
      "F1: 0.9334249226468515\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluate on test data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfe424d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.9907407407407407\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)    \n",
    "# cm_display = ConfusionMatrixDisplay(cm, labels_test).plot()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28aa9a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8224f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
