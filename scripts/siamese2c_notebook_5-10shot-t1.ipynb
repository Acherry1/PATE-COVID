{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b65c72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import utils as utils\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a16c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teachers=5\n",
    "teacher_id = 1\n",
    "epochs = 175\n",
    "shot = 10\n",
    "SIAMESE_MODEL_NAME = '..\\scripts\\models_h5\\siamese_network2c-t{}_{}notebook.h5'.format(teacher_id,shot)\n",
    "EMBEDDING_MODEL_NAME = 'embedding_network2w_0801.h5'\n",
    "if os.path.exists(SIAMESE_MODEL_NAME):\n",
    "    os.remove(SIAMESE_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b86c631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 2 classes.\n",
      "The train set contains 20\n"
     ]
    }
   ],
   "source": [
    "base_dir = r\"F:\\chest project dataset\\dataset\"\n",
    "dataset_path = os.path.join( r\"F:\\chest project dataset\\auto_datasets\", r\"auto_t{}_{}\\t{}-{}\".format(all_teachers,shot,teacher_id, shot))\n",
    "result_file_path = os.path.join(base_dir, r\"true_result_xlsx\")\n",
    "pre_results_path = os.path.join(base_dir, r\"teacher_results_xlsx\",\"result_{}_{}\".format(all_teachers,shot))\n",
    "train_image_list, train_y_list = utils.load_images(dataset_path, 'train', (100, 100))\n",
    "print(\"The train set contains\", len(train_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8942f300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 2 classes.\n",
      "The valid set contains 1200\n"
     ]
    }
   ],
   "source": [
    "test_path = r\"F:\\chest project dataset\\dataset\\pretrain_2c_0727\"\n",
    "valid_image_list, valid_y_list = utils.load_images(test_path, 'valid', (100, 100))\n",
    "print(\"The valid set contains\", len(valid_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ff552f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 2 classes.\n",
      "The test set contains 1200\n"
     ]
    }
   ],
   "source": [
    "test_image_list, test_y_list = utils.load_images(test_path, 'test', (100, 100))\n",
    "print(\"The test set contains\", len(test_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "369794ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 2\n",
      "num_classes: 2\n",
      "num_classes: 2\n"
     ]
    }
   ],
   "source": [
    "# make train pairs\n",
    "pairs_train, labels_train, source_labels_train, true_labels_train = utils.make_pairs(train_image_list, train_y_list)\n",
    "\n",
    "# make validation pairs\n",
    "pairs_val, labels_val, source_labels_val, true_labels_val = utils.make_pairs(valid_image_list, valid_y_list)\n",
    "\n",
    "# make validation pairs\n",
    "pairs_test, labels_test, source_labels_test, true_labels_test = utils.make_pairs(test_image_list, test_y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8959873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c8f79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pairs for train 40\n",
      "number of pairs for validation 2400\n",
      "number of pairs for test 2400\n"
     ]
    }
   ],
   "source": [
    "x_train_1 = pairs_train[:, 0]  # x1(如何给标签带上)\n",
    "x_train_2 = pairs_train[:, 1]  # x2\n",
    "print(\"number of pairs for train\", np.shape(x_train_1)[0])\n",
    "\n",
    "x_val_1 = pairs_val[:, 0]\n",
    "x_val_2 = pairs_val[:, 1]\n",
    "print(\"number of pairs for validation\", np.shape(x_val_1)[0])\n",
    "\n",
    "x_test_1 = pairs_test[:, 0]\n",
    "x_test_2 = pairs_test[:, 1]\n",
    "# print(x_test_1)\n",
    "print(\"number of pairs for test\", np.shape(x_test_1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6955c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(result_file_path):\n",
    "    os.makedirs(result_file_path)\n",
    "result_xlsx=os.path.join(result_file_path,\"true_labels.xlsx\")\n",
    "if not os.path.exists(result_xlsx):\n",
    "    test_1_image_list = x_test_1.tolist()\n",
    "    df = pd.DataFrame({\"image\": test_1_image_list, \"true_label\": true_labels_test})\n",
    "    df.to_excel(result_xlsx, index=False)\n",
    "    df = pd.read_excel(result_xlsx)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.to_excel(result_xlsx, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80363b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 5120)         14739266    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['sequential[0][0]',             \n",
      "                                                                  'sequential[1][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            2           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,739,268\n",
      "Trainable params: 15,362\n",
      "Non-trainable params: 14,723,906\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "input_1 = Input((100, 100, 3))\n",
    "input_2 = Input((100, 100, 3))\n",
    "\n",
    "embedding_network = tf.keras.models.load_model(EMBEDDING_MODEL_NAME)\n",
    "embedding_network.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "for layer in embedding_network.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "model.add(Flatten(name='flat'))\n",
    "model.add(Dense(5120, name='den', activation='sigmoid', kernel_regularizer='l2'))\n",
    "\n",
    "output_1 = model(input_1)\n",
    "output_2 = model(input_2)\n",
    "\n",
    "merge_layer = Lambda(utils.manhattan_distance)([output_1, output_2])\n",
    "output_layer = Dense(1, activation=\"sigmoid\")(merge_layer)\n",
    "siamese = Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c9f7dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, min_delta=0.0001)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=SIAMESE_MODEL_NAME, verbose=1,\n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5b049d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 5120)         14739266    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['sequential[0][0]',             \n",
      "                                                                  'sequential[1][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            2           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,739,268\n",
      "Trainable params: 15,362\n",
      "Non-trainable params: 14,723,906\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.6750\n",
      "Epoch 00001: val_loss improved from inf to 0.33944, saving model to ..\\scripts\\models_h5\\siamese_network2c-t1_10notebook.h5\n",
      "40/40 [==============================] - 220s 6s/step - loss: 0.2167 - accuracy: 0.6750 - val_loss: 0.3394 - val_accuracy: 0.5117 - lr: 1.0000e-04\n",
      "Epoch 2/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.7000\n",
      "Epoch 00002: val_loss improved from 0.33944 to 0.32178, saving model to ..\\scripts\\models_h5\\siamese_network2c-t1_10notebook.h5\n",
      "40/40 [==============================] - 220s 6s/step - loss: 0.2043 - accuracy: 0.7000 - val_loss: 0.3218 - val_accuracy: 0.5192 - lr: 1.0000e-04\n",
      "Epoch 3/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1921 - accuracy: 0.7500\n",
      "Epoch 00003: val_loss improved from 0.32178 to 0.30395, saving model to ..\\scripts\\models_h5\\siamese_network2c-t1_10notebook.h5\n",
      "40/40 [==============================] - 246s 6s/step - loss: 0.1921 - accuracy: 0.7500 - val_loss: 0.3040 - val_accuracy: 0.5329 - lr: 1.0000e-04\n",
      "Epoch 4/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1824 - accuracy: 0.8250\n",
      "Epoch 00004: val_loss improved from 0.30395 to 0.28385, saving model to ..\\scripts\\models_h5\\siamese_network2c-t1_10notebook.h5\n",
      "40/40 [==============================] - 244s 6s/step - loss: 0.1824 - accuracy: 0.8250 - val_loss: 0.2839 - val_accuracy: 0.5467 - lr: 1.0000e-04\n",
      "Epoch 5/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.8250\n",
      "Epoch 00005: val_loss improved from 0.28385 to 0.26845, saving model to ..\\scripts\\models_h5\\siamese_network2c-t1_10notebook.h5\n",
      "40/40 [==============================] - 237s 6s/step - loss: 0.1700 - accuracy: 0.8250 - val_loss: 0.2684 - val_accuracy: 0.5663 - lr: 1.0000e-04\n",
      "Epoch 6/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 0.8250\n",
      "Epoch 00006: val_loss improved from 0.26845 to 0.24870, saving model to ..\\scripts\\models_h5\\siamese_network2c-t1_10notebook.h5\n",
      "40/40 [==============================] - 218s 6s/step - loss: 0.1611 - accuracy: 0.8250 - val_loss: 0.2487 - val_accuracy: 0.5825 - lr: 1.0000e-04\n",
      "Epoch 7/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1510 - accuracy: 0.8250\n",
      "Epoch 00007: val_loss improved from 0.24870 to 0.22937, saving model to ..\\scripts\\models_h5\\siamese_network2c-t1_10notebook.h5\n",
      "40/40 [==============================] - 212s 5s/step - loss: 0.1510 - accuracy: 0.8250 - val_loss: 0.2294 - val_accuracy: 0.6033 - lr: 1.0000e-04\n",
      "Epoch 8/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.8500\n",
      "Epoch 00008: val_loss improved from 0.22937 to 0.21162, saving model to ..\\scripts\\models_h5\\siamese_network2c-t1_10notebook.h5\n",
      "40/40 [==============================] - 213s 5s/step - loss: 0.1438 - accuracy: 0.8500 - val_loss: 0.2116 - val_accuracy: 0.6342 - lr: 1.0000e-04\n",
      "Epoch 9/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.8750\n",
      "Epoch 00009: val_loss did not improve from 0.21162\n",
      "40/40 [==============================] - 229s 6s/step - loss: 0.1400 - accuracy: 0.8750 - val_loss: 0.2122 - val_accuracy: 0.6408 - lr: 1.0000e-04\n",
      "Epoch 10/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.8750\n",
      "Epoch 00010: val_loss improved from 0.21162 to 0.20390, saving model to ..\\scripts\\models_h5\\siamese_network2c-t1_10notebook.h5\n",
      "40/40 [==============================] - 234s 6s/step - loss: 0.1399 - accuracy: 0.8750 - val_loss: 0.2039 - val_accuracy: 0.6604 - lr: 1.0000e-04\n",
      "Epoch 11/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.8750\n",
      "Epoch 00011: val_loss improved from 0.20390 to 0.20148, saving model to ..\\scripts\\models_h5\\siamese_network2c-t1_10notebook.h5\n",
      "40/40 [==============================] - 220s 6s/step - loss: 0.1387 - accuracy: 0.8750 - val_loss: 0.2015 - val_accuracy: 0.6692 - lr: 1.0000e-04\n",
      "Epoch 12/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.9000\n",
      "Epoch 00012: val_loss did not improve from 0.20148\n",
      "40/40 [==============================] - 212s 5s/step - loss: 0.1383 - accuracy: 0.9000 - val_loss: 0.2068 - val_accuracy: 0.6650 - lr: 1.0000e-04\n",
      "Epoch 13/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1380 - accuracy: 0.8750\n",
      "Epoch 00013: val_loss did not improve from 0.20148\n",
      "40/40 [==============================] - 220s 6s/step - loss: 0.1380 - accuracy: 0.8750 - val_loss: 0.2120 - val_accuracy: 0.6604 - lr: 1.0000e-04\n",
      "Epoch 14/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.8750\n",
      "Epoch 00014: val_loss did not improve from 0.20148\n",
      "40/40 [==============================] - 225s 6s/step - loss: 0.1393 - accuracy: 0.8750 - val_loss: 0.2030 - val_accuracy: 0.6762 - lr: 1.0000e-04\n",
      "Epoch 15/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1357 - accuracy: 0.9250\n",
      "Epoch 00015: val_loss did not improve from 0.20148\n",
      "40/40 [==============================] - 215s 6s/step - loss: 0.1357 - accuracy: 0.9250 - val_loss: 0.2068 - val_accuracy: 0.6746 - lr: 1.0000e-04\n",
      "Epoch 16/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.8750\n",
      "Epoch 00016: val_loss did not improve from 0.20148\n",
      "40/40 [==============================] - 227s 6s/step - loss: 0.1352 - accuracy: 0.8750 - val_loss: 0.2032 - val_accuracy: 0.6829 - lr: 1.0000e-04\n",
      "Epoch 17/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9250\n",
      "Epoch 00017: val_loss improved from 0.20148 to 0.19889, saving model to ..\\scripts\\models_h5\\siamese_network2c-t1_10notebook.h5\n",
      "40/40 [==============================] - 222s 6s/step - loss: 0.1346 - accuracy: 0.9250 - val_loss: 0.1989 - val_accuracy: 0.6896 - lr: 2.0000e-05\n",
      "Epoch 18/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9250\n",
      "Epoch 00018: val_loss did not improve from 0.19889\n",
      "40/40 [==============================] - 232s 6s/step - loss: 0.1346 - accuracy: 0.9250 - val_loss: 0.2026 - val_accuracy: 0.6842 - lr: 2.0000e-05\n",
      "Epoch 19/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9250\n",
      "Epoch 00019: val_loss did not improve from 0.19889\n",
      "40/40 [==============================] - 238s 6s/step - loss: 0.1344 - accuracy: 0.9250 - val_loss: 0.1994 - val_accuracy: 0.6896 - lr: 2.0000e-05\n",
      "Epoch 20/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.9250\n",
      "Epoch 00020: val_loss did not improve from 0.19889\n",
      "40/40 [==============================] - 227s 6s/step - loss: 0.1341 - accuracy: 0.9250 - val_loss: 0.2019 - val_accuracy: 0.6850 - lr: 2.0000e-05\n",
      "Epoch 21/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.9250\n",
      "Epoch 00021: val_loss did not improve from 0.19889\n",
      "40/40 [==============================] - 227s 6s/step - loss: 0.1338 - accuracy: 0.9250 - val_loss: 0.1993 - val_accuracy: 0.6904 - lr: 2.0000e-05\n",
      "Epoch 22/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1339 - accuracy: 0.9250\n",
      "Epoch 00022: val_loss improved from 0.19889 to 0.19772, saving model to ..\\scripts\\models_h5\\siamese_network2c-t1_10notebook.h5\n",
      "40/40 [==============================] - 214s 5s/step - loss: 0.1339 - accuracy: 0.9250 - val_loss: 0.1977 - val_accuracy: 0.6933 - lr: 2.0000e-05\n",
      "Epoch 23/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1339 - accuracy: 0.9250\n",
      "Epoch 00023: val_loss did not improve from 0.19772\n",
      "40/40 [==============================] - 217s 6s/step - loss: 0.1339 - accuracy: 0.9250 - val_loss: 0.1987 - val_accuracy: 0.6933 - lr: 2.0000e-05\n",
      "Epoch 24/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1336 - accuracy: 0.9250\n",
      "Epoch 00024: val_loss did not improve from 0.19772\n",
      "40/40 [==============================] - 214s 5s/step - loss: 0.1336 - accuracy: 0.9250 - val_loss: 0.1989 - val_accuracy: 0.6933 - lr: 2.0000e-05\n",
      "Epoch 25/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1334 - accuracy: 0.9250 ETA: 0s - loss: 0.1379 - accura\n",
      "Epoch 00025: val_loss did not improve from 0.19772\n",
      "40/40 [==============================] - 207s 5s/step - loss: 0.1334 - accuracy: 0.9250 - val_loss: 0.1986 - val_accuracy: 0.6933 - lr: 2.0000e-05\n",
      "Epoch 26/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.9250\n",
      "Epoch 00026: val_loss did not improve from 0.19772\n",
      "40/40 [==============================] - 206s 5s/step - loss: 0.1333 - accuracy: 0.9250 - val_loss: 0.1994 - val_accuracy: 0.6933 - lr: 2.0000e-05\n",
      "Epoch 27/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.9250\n",
      "Epoch 00027: val_loss did not improve from 0.19772\n",
      "40/40 [==============================] - 206s 5s/step - loss: 0.1333 - accuracy: 0.9250 - val_loss: 0.1984 - val_accuracy: 0.6954 - lr: 2.0000e-05\n",
      "Epoch 28/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.9250\n",
      "Epoch 00028: val_loss did not improve from 0.19772\n",
      "40/40 [==============================] - 206s 5s/step - loss: 0.1330 - accuracy: 0.9250 - val_loss: 0.1990 - val_accuracy: 0.6942 - lr: 1.0000e-05\n",
      "Epoch 29/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.9250\n",
      "Epoch 00029: val_loss did not improve from 0.19772\n",
      "40/40 [==============================] - 205s 5s/step - loss: 0.1330 - accuracy: 0.9250 - val_loss: 0.1989 - val_accuracy: 0.6950 - lr: 1.0000e-05\n",
      "Epoch 30/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.9250\n",
      "Epoch 00030: val_loss did not improve from 0.19772\n",
      "40/40 [==============================] - 205s 5s/step - loss: 0.1330 - accuracy: 0.9250 - val_loss: 0.1992 - val_accuracy: 0.6946 - lr: 1.0000e-05\n",
      "Epoch 31/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9250\n",
      "Epoch 00031: val_loss did not improve from 0.19772\n",
      "40/40 [==============================] - 207s 5s/step - loss: 0.1329 - accuracy: 0.9250 - val_loss: 0.1987 - val_accuracy: 0.6958 - lr: 1.0000e-05\n",
      "Epoch 32/175\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.9250\n",
      "Epoch 00032: val_loss did not improve from 0.19772\n",
      "40/40 [==============================] - 206s 5s/step - loss: 0.1329 - accuracy: 0.9250 - val_loss: 0.1996 - val_accuracy: 0.6933 - lr: 1.0000e-05\n",
      "Epoch 00032: early stopping\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)\n",
    "siamese.compile(loss=utils.loss(1), optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "# siamese.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "siamese.summary()\n",
    "history = siamese.fit([x_train_1, x_train_2],\n",
    "                      labels_train,\n",
    "                      validation_data=([x_val_1, x_val_2], labels_val),\n",
    "                      batch_size=1,\n",
    "                      epochs=epochs,  # 175 for contrastive 100 for cross ent\n",
    "                      callbacks=[checkpointer, early_stopping, reduce_lr]\n",
    "                      )\n",
    "# print()\n",
    "# Plot the accuracy\n",
    "# utils.plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")\n",
    "\n",
    "# Plot the constrastive loss\n",
    "# utils.plt_metric(history=history.history, metric=\"loss\", title=\"Constrastive Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a897dfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 165s 2s/step - loss: 0.1469 - accuracy: 0.8800\n",
      "test loss, test acc: [0.14691002666950226, 0.8799999952316284]\n"
     ]
    }
   ],
   "source": [
    "results = siamese.evaluate([x_test_1, x_test_2], labels_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5020c970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate on validation data\n",
      "Accuracy: 0.88\n",
      "Precision: 0.9032258064516128\n",
      "Recall: 0.88\n",
      "ROC AUC: 0.88\n",
      "F1: 0.8782467532467532\n"
     ]
    }
   ],
   "source": [
    "Y_pred = siamese.predict([x_test_1, x_test_2]).squeeze()\n",
    "# 返回的是TRUE或FALSE,没有标签数据怎么知道他被分到哪儿个类中？\n",
    "y_pred = Y_pred > 0.5\n",
    "# x1,和x2是否匹配：匹配1，不匹配0\n",
    "y_test = labels_test\n",
    "print(\"\\nEvaluate on validation data\")\n",
    "Accuracy=accuracy_score(y_test, y_pred)\n",
    "Precision=precision_score(y_test, y_pred, average='weighted')\n",
    "Recall=recall_score(y_test, y_pred, average='weighted')\n",
    "ROC_AUC=roc_auc_score(y_test, y_pred, average='weighted')\n",
    "F1=f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"Accuracy:\", Accuracy)\n",
    "print(\"Precision:\", Precision)\n",
    "print(\"Recall:\", Recall)\n",
    "print(\"ROC AUC:\", ROC_AUC)\n",
    "print(\"F1:\",F1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bd41fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1 if i else 0 for i in y_pred]\n",
    "pred_labels = []\n",
    "\n",
    "for i in range(0, len(y_pred)):\n",
    "    if y_pred[i] == 1:\n",
    "        pred_labels += [source_labels_test[i]]\n",
    "    else:\n",
    "        if source_labels_test[i] == 1:\n",
    "            pred_labels += [0.0]\n",
    "        else:\n",
    "            pred_labels += [1.0]\n",
    "a = x_test_1.tolist()\n",
    "df = pd.DataFrame({\"image\": a, \"label_{}\".format(teacher_id): pred_labels})\n",
    "if not os.path.exists(pre_results_path):\n",
    "    os.makedirs(pre_results_path)\n",
    "df.to_excel(os.path.join(pre_results_path,\"{}_{}_{}.xlsx\".format(epochs,teacher_id,shot)),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00ad007f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "plt.show()\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)\n",
    "data_list=[{\"Accuracy\":Accuracy,\"Precision\":Precision,\"Recall\":Recall,\"ROC_AUC\":ROC_AUC,\"tn\":tn,\"fp\":fp,\"fn\":fn,\"tp\":tp,\"specificity\":specificity}]\n",
    "df=pd.DataFrame(data_list)\n",
    "\n",
    "filepath=os.path.join(base_dir,r\"acc_{}_{}\".format(all_teachers,shot))\n",
    "if not os.path.exists(filepath):\n",
    "    os.mkdir(filepath)\n",
    "df.to_excel(os.path.join(filepath,\"{}_{}.xlsx\".format(teacher_id,shot)),index=False)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7080bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
