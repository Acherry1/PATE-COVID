{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b65c72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import utils as utils\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a16c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teachers=2\n",
    "teacher_id = 2\n",
    "epochs = 175\n",
    "shot = 9\n",
    "SIAMESE_MODEL_NAME = '..\\scripts\\models_h5\\siamese_network2c-t{}_{}notebook.h5'.format(teacher_id,shot)\n",
    "EMBEDDING_MODEL_NAME = 'embedding_network2w_0801.h5'\n",
    "if os.path.exists(SIAMESE_MODEL_NAME):\n",
    "    os.remove(SIAMESE_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b86c631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 images belonging to 2 classes.\n",
      "The train set contains 18\n"
     ]
    }
   ],
   "source": [
    "base_dir = r\"..\\scripts\\dataset\"\n",
    "dataset_path = os.path.join( r\"..\\scripts\\auto_datasets\", r\"auto_t{}_{}\\t{}-{}\".format(all_teachers,shot,teacher_id, shot))\n",
    "result_file_path = os.path.join(base_dir, r\"true_result_xlsx\")\n",
    "pre_results_path = os.path.join(base_dir, r\"teacher_results_xlsx\",\"result_{}_{}\".format(all_teachers,shot))\n",
    "train_image_list, train_y_list = utils.load_images(dataset_path, 'train', (100, 100))\n",
    "print(\"The train set contains\", len(train_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8942f300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 2 classes.\n",
      "The valid set contains 1200\n"
     ]
    }
   ],
   "source": [
    "test_path = r\"../scripts/dataset/pretrain_2c_0727/\"\n",
    "valid_image_list, valid_y_list = utils.load_images(test_path, 'valid', (100, 100))\n",
    "print(\"The valid set contains\", len(valid_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ff552f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 2 classes.\n",
      "The test set contains 1200\n"
     ]
    }
   ],
   "source": [
    "test_image_list, test_y_list = utils.load_images(test_path, 'test', (100, 100))\n",
    "print(\"The test set contains\", len(test_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "369794ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 2\n",
      "num_classes: 2\n",
      "num_classes: 2\n"
     ]
    }
   ],
   "source": [
    "# make train pairs\n",
    "pairs_train, labels_train, source_labels_train, true_labels_train = utils.make_pairs(train_image_list, train_y_list)\n",
    "\n",
    "# make validation pairs\n",
    "pairs_val, labels_val, source_labels_val, true_labels_val = utils.make_pairs(valid_image_list, valid_y_list)\n",
    "\n",
    "# make validation pairs\n",
    "pairs_test, labels_test, source_labels_test, true_labels_test = utils.make_pairs(test_image_list, test_y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8959873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c8f79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pairs for train 36\n",
      "number of pairs for validation 2400\n",
      "number of pairs for test 2400\n"
     ]
    }
   ],
   "source": [
    "x_train_1 = pairs_train[:, 0]  # x1(如何给标签带上)\n",
    "x_train_2 = pairs_train[:, 1]  # x2\n",
    "print(\"number of pairs for train\", np.shape(x_train_1)[0])\n",
    "\n",
    "x_val_1 = pairs_val[:, 0]\n",
    "x_val_2 = pairs_val[:, 1]\n",
    "print(\"number of pairs for validation\", np.shape(x_val_1)[0])\n",
    "\n",
    "x_test_1 = pairs_test[:, 0]\n",
    "x_test_2 = pairs_test[:, 1]\n",
    "# print(x_test_1)\n",
    "print(\"number of pairs for test\", np.shape(x_test_1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6955c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(result_file_path):\n",
    "    os.makedirs(result_file_path)\n",
    "result_xlsx=os.path.join(result_file_path,\"true_labels.xlsx\")\n",
    "if not os.path.exists(result_xlsx):\n",
    "    test_1_image_list = x_test_1.tolist()\n",
    "    df = pd.DataFrame({\"image\": test_1_image_list, \"true_label\": true_labels_test})\n",
    "    df.to_excel(result_xlsx, index=False)\n",
    "    df = pd.read_excel(result_xlsx)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.to_excel(result_xlsx, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80363b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 5120)         14739266    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['sequential[0][0]',             \n",
      "                                                                  'sequential[1][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            2           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,739,268\n",
      "Trainable params: 15,362\n",
      "Non-trainable params: 14,723,906\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "input_1 = Input((100, 100, 3))\n",
    "input_2 = Input((100, 100, 3))\n",
    "\n",
    "embedding_network = tf.keras.models.load_model(EMBEDDING_MODEL_NAME)\n",
    "embedding_network.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "for layer in embedding_network.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "model.add(Flatten(name='flat'))\n",
    "model.add(Dense(5120, name='den', activation='sigmoid', kernel_regularizer='l2'))\n",
    "\n",
    "output_1 = model(input_1)\n",
    "output_2 = model(input_2)\n",
    "\n",
    "merge_layer = Lambda(utils.manhattan_distance)([output_1, output_2])\n",
    "output_layer = Dense(1, activation=\"sigmoid\")(merge_layer)\n",
    "siamese = Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c9f7dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, min_delta=0.0001)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=SIAMESE_MODEL_NAME, verbose=1,\n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b049d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 5120)         14739266    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['sequential[0][0]',             \n",
      "                                                                  'sequential[1][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            2           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,739,268\n",
      "Trainable params: 15,362\n",
      "Non-trainable params: 14,723,906\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/175\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1816 - accuracy: 0.6389"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)\n",
    "siamese.compile(loss=utils.loss(1), optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "# siamese.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "siamese.summary()\n",
    "history = siamese.fit([x_train_1, x_train_2],\n",
    "                      labels_train,\n",
    "                      validation_data=([x_val_1, x_val_2], labels_val),\n",
    "                      batch_size=1,\n",
    "                      epochs=epochs,  # 175 for contrastive 100 for cross ent\n",
    "                      callbacks=[checkpointer, early_stopping, reduce_lr]\n",
    "                      )\n",
    "# print()\n",
    "# Plot the accuracy\n",
    "utils.plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")\n",
    "\n",
    "# Plot the constrastive loss\n",
    "utils.plt_metric(history=history.history, metric=\"loss\", title=\"Constrastive Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a897dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = siamese.evaluate([x_test_1, x_test_2], labels_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5020c970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_pred = siamese.predict([x_test_1, x_test_2]).squeeze()\n",
    "# 返回的是TRUE或FALSE,没有标签数据怎么知道他被分到哪儿个类中？\n",
    "y_pred = Y_pred > 0.5\n",
    "# x1,和x2是否匹配：匹配1，不匹配0\n",
    "y_test = labels_test\n",
    "print(\"\\nEvaluate on validation data\")\n",
    "Accuracy=accuracy_score(y_test, y_pred)\n",
    "Precision=precision_score(y_test, y_pred, average='weighted')\n",
    "Recall=recall_score(y_test, y_pred, average='weighted')\n",
    "ROC_AUC=roc_auc_score(y_test, y_pred, average='weighted')\n",
    "F1=f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"Accuracy:\", Accuracy)\n",
    "print(\"Precision:\", Precision)\n",
    "print(\"Recall:\", Recall)\n",
    "print(\"ROC AUC:\", ROC_AUC)\n",
    "print(\"F1:\",F1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd41fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1 if i else 0 for i in y_pred]\n",
    "pred_labels = []\n",
    "\n",
    "for i in range(0, len(y_pred)):\n",
    "    if y_pred[i] == 1:\n",
    "        pred_labels += [source_labels_test[i]]\n",
    "    else:\n",
    "        if source_labels_test[i] == 1:\n",
    "            pred_labels += [0.0]\n",
    "        else:\n",
    "            pred_labels += [1.0]\n",
    "a = x_test_1.tolist()\n",
    "df = pd.DataFrame({\"image\": a, \"label_{}\".format(teacher_id): pred_labels})\n",
    "if not os.path.exists(pre_results_path):\n",
    "    os.makedirs(pre_results_path)\n",
    "df.to_excel(os.path.join(pre_results_path,\"{}_{}_{}.xlsx\".format(epochs,teacher_id,shot)),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "plt.show()\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)\n",
    "data_list=[{\"Accuracy\":Accuracy,\"Precision\":Precision,\"Recall\":Recall,\"ROC_AUC\":ROC_AUC,\"tn\":tn,\"fp\":fp,\"fn\":fn,\"tp\":tp,\"specificity\":specificity}]\n",
    "df=pd.DataFrame(data_list)\n",
    "\n",
    "filepath=os.path.join(base_dir,r\"acc_{}_{}\".format(all_teachers,shot))\n",
    "if not os.path.exists(filepath):\n",
    "    os.mkdir(filepath)\n",
    "df.to_excel(os.path.join(filepath,\"{}_{}.xlsx\".format(teacher_id,shot)),index=False)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7080bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
