{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b65c72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import utils as utils\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a16c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teachers=5\n",
    "teacher_id = 3\n",
    "epochs = 175\n",
    "shot = 20\n",
    "SIAMESE_MODEL_NAME = '..\\scripts\\models_h5\\siamese_network2c-t{}_{}notebook.h5'.format(teacher_id,shot)\n",
    "EMBEDDING_MODEL_NAME = 'embedding_network2w_0726.h5'\n",
    "if os.path.exists(SIAMESE_MODEL_NAME):\n",
    "    os.remove(SIAMESE_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b86c631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n",
      "The train set contains 40\n"
     ]
    }
   ],
   "source": [
    "base_dir = r\"..\\scripts\\dataset\"\n",
    "dataset_path = os.path.join(base_dir, r\"t{}-{}\".format(teacher_id, shot))\n",
    "result_file_path = os.path.join(base_dir, r\"true_result_xlsx\\true_labels.xlsx\")\n",
    "pre_results_path = os.path.join(base_dir, r\"teacher_results_xlsx\\result_{}_{}\\{}_{}_{}.xlsx\".format(all_teachers,shot,epochs,teacher_id,shot))\n",
    "train_image_list, train_y_list = utils.load_images(dataset_path, 'train', (100, 100))\n",
    "print(\"The train set contains\", len(train_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8942f300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 132 images belonging to 2 classes.\n",
      "The valid set contains 132\n"
     ]
    }
   ],
   "source": [
    "test_path = r\"..\\scripts\\dataset\\pretrain2w\"\n",
    "valid_image_list, valid_y_list = utils.load_images(test_path, 'test', (100, 100))\n",
    "print(\"The valid set contains\", len(valid_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ff552f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 132 images belonging to 2 classes.\n",
      "The test set contains 132\n"
     ]
    }
   ],
   "source": [
    "test_image_list, test_y_list = utils.load_images(test_path, 'test', (100, 100))\n",
    "print(\"The test set contains\", len(test_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "369794ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 2\n",
      "num_classes: 2\n",
      "num_classes: 2\n"
     ]
    }
   ],
   "source": [
    "# make train pairs\n",
    "pairs_train, labels_train, source_labels_train, true_labels_train = utils.make_pairs(train_image_list, train_y_list)\n",
    "\n",
    "# make validation pairs\n",
    "pairs_val, labels_val, source_labels_val, true_labels_val = utils.make_pairs(valid_image_list, valid_y_list)\n",
    "\n",
    "# make validation pairs\n",
    "pairs_test, labels_test, source_labels_test, true_labels_test = utils.make_pairs(test_image_list, test_y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8959873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c8f79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pairs for train 80\n",
      "number of pairs for validation 264\n",
      "number of pairs for test 264\n"
     ]
    }
   ],
   "source": [
    "x_train_1 = pairs_train[:, 0]  # x1(如何给标签带上)\n",
    "x_train_2 = pairs_train[:, 1]  # x2\n",
    "print(\"number of pairs for train\", np.shape(x_train_1)[0])\n",
    "\n",
    "x_val_1 = pairs_val[:, 0]\n",
    "x_val_2 = pairs_val[:, 1]\n",
    "print(\"number of pairs for validation\", np.shape(x_val_1)[0])\n",
    "\n",
    "x_test_1 = pairs_test[:, 0]\n",
    "x_test_2 = pairs_test[:, 1]\n",
    "# print(x_test_1)\n",
    "print(\"number of pairs for test\", np.shape(x_test_1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6955c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(result_file_path):\n",
    "    test_1_image_list = x_test_1.tolist()\n",
    "    df = pd.DataFrame({\"image\": test_1_image_list, \"true_label\": true_labels_test})\n",
    "    df.to_excel(result_file_path, index=False)\n",
    "    df = pd.read_excel(result_file_path)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.to_excel(result_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80363b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 5120)         14739266    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['sequential[0][0]',             \n",
      "                                                                  'sequential[1][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            2           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,739,268\n",
      "Trainable params: 15,362\n",
      "Non-trainable params: 14,723,906\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "input_1 = Input((100, 100, 3))\n",
    "input_2 = Input((100, 100, 3))\n",
    "\n",
    "embedding_network = tf.keras.models.load_model(EMBEDDING_MODEL_NAME)\n",
    "embedding_network.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "for layer in embedding_network.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "model.add(Flatten(name='flat'))\n",
    "model.add(Dense(5120, name='den', activation='sigmoid', kernel_regularizer='l2'))\n",
    "\n",
    "output_1 = model(input_1)\n",
    "output_2 = model(input_2)\n",
    "\n",
    "merge_layer = Lambda(utils.manhattan_distance)([output_1, output_2])\n",
    "output_layer = Dense(1, activation=\"sigmoid\")(merge_layer)\n",
    "siamese = Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c9f7dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, min_delta=0.0001)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=SIAMESE_MODEL_NAME, verbose=1,\n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5aae2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 5120)         14739266    ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['sequential[0][0]',             \n",
      "                                                                  'sequential[1][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            2           ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,739,268\n",
      "Trainable params: 15,362\n",
      "Non-trainable params: 14,723,906\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.6625\n",
      "Epoch 00001: val_loss improved from inf to 0.20748, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 40s 457ms/step - loss: 0.1612 - accuracy: 0.6625 - val_loss: 0.2075 - val_accuracy: 0.6705 - lr: 1.0000e-04\n",
      "Epoch 2/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1437 - accuracy: 0.7875\n",
      "Epoch 00002: val_loss improved from 0.20748 to 0.18403, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 35s 442ms/step - loss: 0.1437 - accuracy: 0.7875 - val_loss: 0.1840 - val_accuracy: 0.7045 - lr: 1.0000e-04\n",
      "Epoch 3/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.8500\n",
      "Epoch 00003: val_loss improved from 0.18403 to 0.16597, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 449ms/step - loss: 0.1330 - accuracy: 0.8500 - val_loss: 0.1660 - val_accuracy: 0.7576 - lr: 1.0000e-04\n",
      "Epoch 4/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.9250\n",
      "Epoch 00004: val_loss improved from 0.16597 to 0.15132, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 35s 448ms/step - loss: 0.1271 - accuracy: 0.9250 - val_loss: 0.1513 - val_accuracy: 0.7955 - lr: 1.0000e-04\n",
      "Epoch 5/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9625\n",
      "Epoch 00005: val_loss improved from 0.15132 to 0.14810, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 450ms/step - loss: 0.1243 - accuracy: 0.9625 - val_loss: 0.1481 - val_accuracy: 0.8106 - lr: 1.0000e-04\n",
      "Epoch 6/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9750\n",
      "Epoch 00006: val_loss did not improve from 0.14810\n",
      "80/80 [==============================] - 35s 447ms/step - loss: 0.1230 - accuracy: 0.9750 - val_loss: 0.1536 - val_accuracy: 0.8030 - lr: 1.0000e-04\n",
      "Epoch 7/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9750\n",
      "Epoch 00007: val_loss improved from 0.14810 to 0.14809, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 35s 447ms/step - loss: 0.1221 - accuracy: 0.9750 - val_loss: 0.1481 - val_accuracy: 0.8258 - lr: 1.0000e-04\n",
      "Epoch 8/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9875\n",
      "Epoch 00008: val_loss improved from 0.14809 to 0.14589, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 449ms/step - loss: 0.1212 - accuracy: 0.9875 - val_loss: 0.1459 - val_accuracy: 0.8523 - lr: 1.0000e-04\n",
      "Epoch 9/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9875\n",
      "Epoch 00009: val_loss did not improve from 0.14589\n",
      "80/80 [==============================] - 35s 445ms/step - loss: 0.1205 - accuracy: 0.9875 - val_loss: 0.1461 - val_accuracy: 0.8523 - lr: 1.0000e-04\n",
      "Epoch 10/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.9875\n",
      "Epoch 00010: val_loss did not improve from 0.14589\n",
      "80/80 [==============================] - 35s 445ms/step - loss: 0.1198 - accuracy: 0.9875 - val_loss: 0.1464 - val_accuracy: 0.8636 - lr: 1.0000e-04\n",
      "Epoch 11/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.9875\n",
      "Epoch 00011: val_loss improved from 0.14589 to 0.14470, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 448ms/step - loss: 0.1191 - accuracy: 0.9875 - val_loss: 0.1447 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
      "Epoch 12/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.98 - ETA: 0s - loss: 0.1185 - accuracy: 0.9875\n",
      "Epoch 00012: val_loss improved from 0.14470 to 0.14215, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 449ms/step - loss: 0.1185 - accuracy: 0.9875 - val_loss: 0.1422 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
      "Epoch 13/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9875\n",
      "Epoch 00013: val_loss did not improve from 0.14215\n",
      "80/80 [==============================] - 35s 444ms/step - loss: 0.1178 - accuracy: 0.9875 - val_loss: 0.1445 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
      "Epoch 14/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1171 - accuracy: 0.9875\n",
      "Epoch 00014: val_loss improved from 0.14215 to 0.14175, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 35s 448ms/step - loss: 0.1171 - accuracy: 0.9875 - val_loss: 0.1417 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
      "Epoch 15/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.9875\n",
      "Epoch 00015: val_loss did not improve from 0.14175\n",
      "80/80 [==============================] - 35s 441ms/step - loss: 0.1165 - accuracy: 0.9875 - val_loss: 0.1423 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
      "Epoch 16/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1158 - accuracy: 1.0000\n",
      "Epoch 00016: val_loss did not improve from 0.14175\n",
      "80/80 [==============================] - 35s 444ms/step - loss: 0.1158 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
      "Epoch 17/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 1.0000\n",
      "Epoch 00017: val_loss improved from 0.14175 to 0.14098, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 35s 448ms/step - loss: 0.1151 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
      "Epoch 18/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 1.0000\n",
      "Epoch 00018: val_loss improved from 0.14098 to 0.13918, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 35s 445ms/step - loss: 0.1145 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.8826 - lr: 1.0000e-04\n",
      "Epoch 19/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 1.0000\n",
      "Epoch 00019: val_loss did not improve from 0.13918\n",
      "80/80 [==============================] - 35s 447ms/step - loss: 0.1138 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.8826 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 1.0000\n",
      "Epoch 00020: val_loss did not improve from 0.13918\n",
      "80/80 [==============================] - 35s 445ms/step - loss: 0.1132 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.8788 - lr: 1.0000e-04\n",
      "Epoch 21/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 1.0000 ETA: 0s - loss: 0.1138 \n",
      "Epoch 00021: val_loss improved from 0.13918 to 0.13665, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 35s 446ms/step - loss: 0.1125 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.8902 - lr: 1.0000e-04\n",
      "Epoch 22/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 1.0000\n",
      "Epoch 00022: val_loss did not improve from 0.13665\n",
      "80/80 [==============================] - 35s 446ms/step - loss: 0.1119 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.8864 - lr: 1.0000e-04\n",
      "Epoch 23/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 1.0000\n",
      "Epoch 00023: val_loss did not improve from 0.13665\n",
      "80/80 [==============================] - 35s 445ms/step - loss: 0.1112 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8902 - lr: 1.0000e-04\n",
      "Epoch 24/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 1.0000\n",
      "Epoch 00024: val_loss improved from 0.13665 to 0.13588, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 35s 446ms/step - loss: 0.1106 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.8939 - lr: 1.0000e-04\n",
      "Epoch 25/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 1.0000\n",
      "Epoch 00025: val_loss improved from 0.13588 to 0.13493, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 449ms/step - loss: 0.1100 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.8977 - lr: 1.0000e-04\n",
      "Epoch 26/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 1.0000\n",
      "Epoch 00026: val_loss improved from 0.13493 to 0.13477, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 35s 448ms/step - loss: 0.1093 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.8977 - lr: 1.0000e-04\n",
      "Epoch 27/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 1.0000\n",
      "Epoch 00027: val_loss did not improve from 0.13477\n",
      "80/80 [==============================] - 35s 446ms/step - loss: 0.1087 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.8864 - lr: 1.0000e-04\n",
      "Epoch 28/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 1.0000\n",
      "Epoch 00028: val_loss improved from 0.13477 to 0.13236, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 448ms/step - loss: 0.1081 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 29/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 1.0000\n",
      "Epoch 00029: val_loss did not improve from 0.13236\n",
      "80/80 [==============================] - 35s 446ms/step - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9205 - lr: 1.0000e-04\n",
      "Epoch 30/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 1.0000\n",
      "Epoch 00030: val_loss improved from 0.13236 to 0.13046, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 35s 446ms/step - loss: 0.1068 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 31/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 1.0000\n",
      "Epoch 00031: val_loss did not improve from 0.13046\n",
      "80/80 [==============================] - 35s 446ms/step - loss: 0.1062 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.8977 - lr: 1.0000e-04\n",
      "Epoch 32/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1055 - accuracy: 1.0000\n",
      "Epoch 00032: val_loss did not improve from 0.13046\n",
      "80/80 [==============================] - 35s 445ms/step - loss: 0.1055 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 33/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1049 - accuracy: 1.0000\n",
      "Epoch 00033: val_loss did not improve from 0.13046\n",
      "80/80 [==============================] - 35s 446ms/step - loss: 0.1049 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 34/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1043 - accuracy: 1.0000\n",
      "Epoch 00034: val_loss did not improve from 0.13046\n",
      "80/80 [==============================] - 35s 445ms/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 35/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 1.0000\n",
      "Epoch 00035: val_loss improved from 0.13046 to 0.13009, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 449ms/step - loss: 0.1037 - accuracy: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 36/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1031 - accuracy: 1.0000\n",
      "Epoch 00036: val_loss improved from 0.13009 to 0.12850, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 448ms/step - loss: 0.1031 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 37/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 1.0000\n",
      "Epoch 00037: val_loss did not improve from 0.12850\n",
      "80/80 [==============================] - 35s 446ms/step - loss: 0.1025 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 38/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 1.0000\n",
      "Epoch 00038: val_loss improved from 0.12850 to 0.12584, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 456ms/step - loss: 0.1018 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 39/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 1.0000\n",
      "Epoch 00039: val_loss did not improve from 0.12584\n",
      "80/80 [==============================] - 36s 449ms/step - loss: 0.1013 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 40/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 1.0000\n",
      "Epoch 00040: val_loss did not improve from 0.12584\n",
      "80/80 [==============================] - 36s 450ms/step - loss: 0.1006 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 41/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 1.0000\n",
      "Epoch 00041: val_loss did not improve from 0.12584\n",
      "80/80 [==============================] - 36s 454ms/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 42/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 1.0000\n",
      "Epoch 00042: val_loss improved from 0.12584 to 0.12504, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 456ms/step - loss: 0.0995 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 43/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 1.0000\n",
      "Epoch 00043: val_loss improved from 0.12504 to 0.12362, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 457ms/step - loss: 0.0989 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9318 - lr: 1.0000e-04\n",
      "Epoch 44/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 1.0000\n",
      "Epoch 00044: val_loss did not improve from 0.12362\n",
      "80/80 [==============================] - 36s 456ms/step - loss: 0.0983 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 45/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 1.0000\n",
      "Epoch 00045: val_loss improved from 0.12362 to 0.12247, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 455ms/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9318 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 1.0000\n",
      "Epoch 00046: val_loss did not improve from 0.12247\n",
      "80/80 [==============================] - 36s 456ms/step - loss: 0.0971 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 47/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 1.0000\n",
      "Epoch 00047: val_loss did not improve from 0.12247\n",
      "80/80 [==============================] - 36s 455ms/step - loss: 0.0965 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 48/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0959 - accuracy: 1.0000\n",
      "Epoch 00048: val_loss improved from 0.12247 to 0.12223, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9318 - lr: 1.0000e-04\n",
      "Epoch 49/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 1.0000\n",
      "Epoch 00049: val_loss did not improve from 0.12223\n",
      "80/80 [==============================] - 36s 452ms/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 50/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 1.0000\n",
      "Epoch 00050: val_loss improved from 0.12223 to 0.12158, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 456ms/step - loss: 0.0948 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9318 - lr: 1.0000e-04\n",
      "Epoch 51/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 1.0000\n",
      "Epoch 00051: val_loss did not improve from 0.12158\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 0.0942 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 52/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 1.0000\n",
      "Epoch 00052: val_loss improved from 0.12158 to 0.11994, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 455ms/step - loss: 0.0937 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9318 - lr: 1.0000e-04\n",
      "Epoch 53/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 1.0000\n",
      "Epoch 00053: val_loss did not improve from 0.11994\n",
      "80/80 [==============================] - 36s 450ms/step - loss: 0.0930 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9318 - lr: 1.0000e-04\n",
      "Epoch 54/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 1.0000\n",
      "Epoch 00054: val_loss did not improve from 0.11994\n",
      "80/80 [==============================] - 36s 452ms/step - loss: 0.0925 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Epoch 55/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 1.0000\n",
      "Epoch 00055: val_loss improved from 0.11994 to 0.11926, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 451ms/step - loss: 0.0919 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9318 - lr: 1.0000e-04\n",
      "Epoch 56/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 1.0000\n",
      "Epoch 00056: val_loss improved from 0.11926 to 0.11828, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 452ms/step - loss: 0.0914 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9318 - lr: 1.0000e-04\n",
      "Epoch 57/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 1.0000\n",
      "Epoch 00057: val_loss did not improve from 0.11828\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 0.0908 - accuracy: 1.0000 - val_loss: 0.1187 - val_accuracy: 0.9318 - lr: 1.0000e-04\n",
      "Epoch 58/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 1.0000\n",
      "Epoch 00058: val_loss improved from 0.11828 to 0.11633, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 0.0902 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 0.9394 - lr: 1.0000e-04\n",
      "Epoch 59/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 1.0000\n",
      "Epoch 00059: val_loss improved from 0.11633 to 0.11571, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 452ms/step - loss: 0.0896 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9470 - lr: 1.0000e-04\n",
      "Epoch 60/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 1.0000\n",
      "Epoch 00060: val_loss did not improve from 0.11571\n",
      "80/80 [==============================] - 36s 452ms/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9318 - lr: 1.0000e-04\n",
      "Epoch 61/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 1.0000\n",
      "Epoch 00061: val_loss improved from 0.11571 to 0.11495, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 455ms/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9470 - lr: 1.0000e-04\n",
      "Epoch 62/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 1.0000\n",
      "Epoch 00062: val_loss improved from 0.11495 to 0.11493, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 454ms/step - loss: 0.0880 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9394 - lr: 1.0000e-04\n",
      "Epoch 63/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 1.0000\n",
      "Epoch 00063: val_loss improved from 0.11493 to 0.11401, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 0.0875 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 0.9470 - lr: 1.0000e-04\n",
      "Epoch 64/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 1.0000\n",
      "Epoch 00064: val_loss did not improve from 0.11401\n",
      "80/80 [==============================] - 36s 451ms/step - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9394 - lr: 1.0000e-04\n",
      "Epoch 65/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 1.0000\n",
      "Epoch 00065: val_loss improved from 0.11401 to 0.11172, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 457ms/step - loss: 0.0864 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9470 - lr: 1.0000e-04\n",
      "Epoch 66/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 1.0000\n",
      "Epoch 00066: val_loss improved from 0.11172 to 0.11134, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 0.0859 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9470 - lr: 1.0000e-04\n",
      "Epoch 67/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 1.0000\n",
      "Epoch 00067: val_loss did not improve from 0.11134\n",
      "80/80 [==============================] - 36s 454ms/step - loss: 0.0853 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9470 - lr: 1.0000e-04\n",
      "Epoch 68/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 1.0000\n",
      "Epoch 00068: val_loss did not improve from 0.11134\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9394 - lr: 1.0000e-04\n",
      "Epoch 69/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 1.0000\n",
      "Epoch 00069: val_loss improved from 0.11134 to 0.11059, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 452ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9470 - lr: 1.0000e-04\n",
      "Epoch 70/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 1.0000\n",
      "Epoch 00070: val_loss improved from 0.11059 to 0.11004, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 452ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9470 - lr: 1.0000e-04\n",
      "Epoch 71/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 1.0000\n",
      "Epoch 00071: val_loss did not improve from 0.11004\n",
      "80/80 [==============================] - 36s 451ms/step - loss: 0.0832 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9394 - lr: 1.0000e-04\n",
      "Epoch 72/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 1.0000\n",
      "Epoch 00072: val_loss improved from 0.11004 to 0.10938, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 454ms/step - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9470 - lr: 1.0000e-04\n",
      "Epoch 73/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 1.0000\n",
      "Epoch 00073: val_loss did not improve from 0.10938\n",
      "80/80 [==============================] - 36s 449ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9470 - lr: 1.0000e-04\n",
      "Epoch 74/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 1.0000\n",
      "Epoch 00074: val_loss did not improve from 0.10938\n",
      "80/80 [==============================] - 36s 454ms/step - loss: 0.0816 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9470 - lr: 1.0000e-04\n",
      "Epoch 75/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 1.0000\n",
      "Epoch 00075: val_loss improved from 0.10938 to 0.10773, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 458ms/step - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 76/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 1.0000\n",
      "Epoch 00076: val_loss did not improve from 0.10773\n",
      "80/80 [==============================] - 36s 452ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9470 - lr: 1.0000e-04\n",
      "Epoch 77/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 1.0000\n",
      "Epoch 00077: val_loss improved from 0.10773 to 0.10542, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 0.0801 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 78/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 1.0000\n",
      "Epoch 00078: val_loss did not improve from 0.10542\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9394 - lr: 1.0000e-04\n",
      "Epoch 79/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 1.0000\n",
      "Epoch 00079: val_loss did not improve from 0.10542\n",
      "80/80 [==============================] - 36s 454ms/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 80/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 1.0000\n",
      "Epoch 00080: val_loss did not improve from 0.10542\n",
      "80/80 [==============================] - 36s 455ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 81/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 1.0000\n",
      "Epoch 00081: val_loss did not improve from 0.10542\n",
      "80/80 [==============================] - 36s 454ms/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 82/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 1.0000\n",
      "Epoch 00082: val_loss improved from 0.10542 to 0.10276, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 454ms/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 83/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 1.0000\n",
      "Epoch 00083: val_loss did not improve from 0.10276\n",
      "80/80 [==============================] - 36s 454ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 84/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 1.0000\n",
      "Epoch 00084: val_loss did not improve from 0.10276\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 85/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 1.0000\n",
      "Epoch 00085: val_loss did not improve from 0.10276\n",
      "80/80 [==============================] - 36s 453ms/step - loss: 0.0761 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 86/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 1.0000\n",
      "Epoch 00086: val_loss improved from 0.10276 to 0.10260, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 457ms/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 87/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 1.0000\n",
      "Epoch 00087: val_loss improved from 0.10260 to 0.10132, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 455ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 88/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 1.0000\n",
      "Epoch 00088: val_loss did not improve from 0.10132\n",
      "80/80 [==============================] - 36s 455ms/step - loss: 0.0746 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 89/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 1.0000\n",
      "Epoch 00089: val_loss improved from 0.10132 to 0.10098, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 454ms/step - loss: 0.0741 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 90/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 1.0000\n",
      "Epoch 00090: val_loss improved from 0.10098 to 0.10047, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 454ms/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 91/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0732 - accuracy: 1.0000\n",
      "Epoch 00091: val_loss improved from 0.10047 to 0.09946, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 454ms/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 92/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 1.0000\n",
      "Epoch 00092: val_loss improved from 0.09946 to 0.09937, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 36s 451ms/step - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 93/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 1.0000\n",
      "Epoch 00093: val_loss improved from 0.09937 to 0.09817, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 38s 478ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 94/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 1.0000\n",
      "Epoch 00094: val_loss did not improve from 0.09817\n",
      "80/80 [==============================] - 38s 479ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 95/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 1.0000\n",
      "Epoch 00095: val_loss did not improve from 0.09817\n",
      "80/80 [==============================] - 38s 476ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 96/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 1.0000\n",
      "Epoch 00096: val_loss did not improve from 0.09817\n",
      "80/80 [==============================] - 38s 478ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9545 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 1.0000\n",
      "Epoch 00097: val_loss improved from 0.09817 to 0.09747, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 38s 482ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 98/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 1.0000\n",
      "Epoch 00098: val_loss did not improve from 0.09747\n",
      "80/80 [==============================] - 38s 475ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 99/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 1.0000\n",
      "Epoch 00099: val_loss improved from 0.09747 to 0.09490, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 38s 479ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 100/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 1.0000\n",
      "Epoch 00100: val_loss did not improve from 0.09490\n",
      "80/80 [==============================] - 38s 480ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 101/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 1.0000\n",
      "Epoch 00101: val_loss did not improve from 0.09490\n",
      "80/80 [==============================] - 38s 475ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 102/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 1.0000\n",
      "Epoch 00102: val_loss did not improve from 0.09490\n",
      "80/80 [==============================] - 38s 476ms/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 103/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 1.0000\n",
      "Epoch 00103: val_loss did not improve from 0.09490\n",
      "80/80 [==============================] - 38s 479ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 104/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 1.0000\n",
      "Epoch 00104: val_loss improved from 0.09490 to 0.09329, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 28384s 359s/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 105/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 1.0000\n",
      "Epoch 00105: val_loss improved from 0.09329 to 0.09250, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 34s 431ms/step - loss: 0.0667 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 106/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 1.0000\n",
      "Epoch 00106: val_loss did not improve from 0.09250\n",
      "80/80 [==============================] - 32s 406ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 107/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 1.0000\n",
      "Epoch 00107: val_loss did not improve from 0.09250\n",
      "80/80 [==============================] - 31s 396ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 108/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 1.0000\n",
      "Epoch 00108: val_loss did not improve from 0.09250\n",
      "80/80 [==============================] - 33s 414ms/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 109/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 1.0000\n",
      "Epoch 00109: val_loss improved from 0.09250 to 0.09047, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 32s 408ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 110/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 1.0000\n",
      "Epoch 00110: val_loss did not improve from 0.09047\n",
      "80/80 [==============================] - 32s 405ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 111/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 1.0000\n",
      "Epoch 00111: val_loss improved from 0.09047 to 0.08952, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 384ms/step - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 112/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 1.0000\n",
      "Epoch 00112: val_loss did not improve from 0.08952\n",
      "80/80 [==============================] - 30s 384ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 113/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 1.0000\n",
      "Epoch 00113: val_loss did not improve from 0.08952\n",
      "80/80 [==============================] - 31s 389ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 114/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 1.0000\n",
      "Epoch 00114: val_loss did not improve from 0.08952\n",
      "80/80 [==============================] - 30s 382ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 115/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 1.0000\n",
      "Epoch 00115: val_loss did not improve from 0.08952\n",
      "80/80 [==============================] - 30s 378ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 116/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 1.0000\n",
      "Epoch 00116: val_loss did not improve from 0.08952\n",
      "80/80 [==============================] - 30s 379ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 117/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 1.0000\n",
      "Epoch 00117: val_loss improved from 0.08952 to 0.08929, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 31s 389ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9583 - lr: 2.0000e-05\n",
      "Epoch 118/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 1.0000\n",
      "Epoch 00118: val_loss improved from 0.08929 to 0.08874, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 384ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9583 - lr: 2.0000e-05\n",
      "Epoch 119/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 1.0000\n",
      "Epoch 00119: val_loss did not improve from 0.08874\n",
      "80/80 [==============================] - 31s 389ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9583 - lr: 2.0000e-05\n",
      "Epoch 120/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 1.0000\n",
      "Epoch 00120: val_loss did not improve from 0.08874\n",
      "80/80 [==============================] - 30s 379ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9583 - lr: 2.0000e-05\n",
      "Epoch 121/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 1.0000\n",
      "Epoch 00121: val_loss improved from 0.08874 to 0.08850, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 380ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9583 - lr: 2.0000e-05\n",
      "Epoch 122/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 1.0000\n",
      "Epoch 00122: val_loss did not improve from 0.08850\n",
      "80/80 [==============================] - 30s 382ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9583 - lr: 2.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 1.0000\n",
      "Epoch 00123: val_loss improved from 0.08850 to 0.08833, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 379ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9583 - lr: 2.0000e-05\n",
      "Epoch 124/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 1.0000\n",
      "Epoch 00124: val_loss improved from 0.08833 to 0.08807, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 382ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9583 - lr: 2.0000e-05\n",
      "Epoch 125/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 1.0000\n",
      "Epoch 00125: val_loss did not improve from 0.08807\n",
      "80/80 [==============================] - 30s 382ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9583 - lr: 2.0000e-05\n",
      "Epoch 126/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 1.0000\n",
      "Epoch 00126: val_loss improved from 0.08807 to 0.08794, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 380ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9583 - lr: 2.0000e-05\n",
      "Epoch 127/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 1.0000\n",
      "Epoch 00127: val_loss did not improve from 0.08794\n",
      "80/80 [==============================] - 30s 384ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9583 - lr: 2.0000e-05\n",
      "Epoch 128/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 1.0000\n",
      "Epoch 00128: val_loss did not improve from 0.08794\n",
      "80/80 [==============================] - 30s 377ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9583 - lr: 2.0000e-05\n",
      "Epoch 129/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 1.0000\n",
      "Epoch 00129: val_loss did not improve from 0.08794\n",
      "80/80 [==============================] - 30s 378ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9583 - lr: 2.0000e-05\n",
      "Epoch 130/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 1.0000\n",
      "Epoch 00130: val_loss did not improve from 0.08794\n",
      "80/80 [==============================] - 30s 375ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9583 - lr: 2.0000e-05\n",
      "Epoch 131/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 1.0000\n",
      "Epoch 00131: val_loss did not improve from 0.08794\n",
      "80/80 [==============================] - 30s 375ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9583 - lr: 2.0000e-05\n",
      "Epoch 132/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 1.0000\n",
      "Epoch 00132: val_loss improved from 0.08794 to 0.08773, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 379ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 133/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 1.0000\n",
      "Epoch 00133: val_loss improved from 0.08773 to 0.08770, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 382ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 134/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 1.0000\n",
      "Epoch 00134: val_loss did not improve from 0.08770\n",
      "80/80 [==============================] - 30s 383ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 135/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 1.0000\n",
      "Epoch 00135: val_loss improved from 0.08770 to 0.08760, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 380ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 136/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 1.0000\n",
      "Epoch 00136: val_loss did not improve from 0.08760\n",
      "80/80 [==============================] - 30s 381ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 137/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 1.0000\n",
      "Epoch 00137: val_loss improved from 0.08760 to 0.08755, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 381ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 138/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 1.0000\n",
      "Epoch 00138: val_loss improved from 0.08755 to 0.08727, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 32s 399ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 139/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 1.0000\n",
      "Epoch 00139: val_loss did not improve from 0.08727\n",
      "80/80 [==============================] - 31s 397ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 140/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 1.0000\n",
      "Epoch 00140: val_loss did not improve from 0.08727\n",
      "80/80 [==============================] - 30s 382ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 141/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 1.0000\n",
      "Epoch 00141: val_loss did not improve from 0.08727\n",
      "80/80 [==============================] - 30s 380ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 142/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 1.0000\n",
      "Epoch 00142: val_loss improved from 0.08727 to 0.08707, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 379ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 143/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 1.0000\n",
      "Epoch 00143: val_loss did not improve from 0.08707\n",
      "80/80 [==============================] - 30s 380ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 144/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 1.0000\n",
      "Epoch 00144: val_loss did not improve from 0.08707\n",
      "80/80 [==============================] - 30s 377ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 145/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 1.0000\n",
      "Epoch 00145: val_loss did not improve from 0.08707\n",
      "80/80 [==============================] - 30s 377ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 146/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 1.0000\n",
      "Epoch 00146: val_loss did not improve from 0.08707\n",
      "80/80 [==============================] - 31s 397ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 147/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 1.0000\n",
      "Epoch 00147: val_loss did not improve from 0.08707\n",
      "80/80 [==============================] - 30s 376ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 148/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 1.0000\n",
      "Epoch 00148: val_loss improved from 0.08707 to 0.08694, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 378ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9583 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 1.0000\n",
      "Epoch 00149: val_loss improved from 0.08694 to 0.08680, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 37s 463ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 150/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 1.0000\n",
      "Epoch 00150: val_loss improved from 0.08680 to 0.08679, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 34s 424ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 151/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 1.0000\n",
      "Epoch 00151: val_loss improved from 0.08679 to 0.08674, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 34s 429ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 152/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 1.0000\n",
      "Epoch 00152: val_loss did not improve from 0.08674\n",
      "80/80 [==============================] - 34s 425ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 153/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 1.0000\n",
      "Epoch 00153: val_loss did not improve from 0.08674\n",
      "80/80 [==============================] - 30s 382ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 154/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 1.0000\n",
      "Epoch 00154: val_loss did not improve from 0.08674\n",
      "80/80 [==============================] - 30s 377ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 155/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 1.0000\n",
      "Epoch 00155: val_loss did not improve from 0.08674\n",
      "80/80 [==============================] - 30s 376ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 156/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 1.0000\n",
      "Epoch 00156: val_loss improved from 0.08674 to 0.08655, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 382ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 157/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 1.0000\n",
      "Epoch 00157: val_loss improved from 0.08655 to 0.08631, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 383ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 158/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 1.0000\n",
      "Epoch 00158: val_loss improved from 0.08631 to 0.08609, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 382ms/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 159/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 1.0000\n",
      "Epoch 00159: val_loss did not improve from 0.08609\n",
      "80/80 [==============================] - 30s 385ms/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 160/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 1.0000\n",
      "Epoch 00160: val_loss did not improve from 0.08609\n",
      "80/80 [==============================] - 30s 381ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 161/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 1.0000\n",
      "Epoch 00161: val_loss did not improve from 0.08609\n",
      "80/80 [==============================] - 30s 381ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 162/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 1.0000\n",
      "Epoch 00162: val_loss did not improve from 0.08609\n",
      "80/80 [==============================] - 30s 384ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 163/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 1.0000\n",
      "Epoch 00163: val_loss did not improve from 0.08609\n",
      "80/80 [==============================] - 31s 395ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 164/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 1.0000\n",
      "Epoch 00164: val_loss did not improve from 0.08609\n",
      "80/80 [==============================] - 30s 379ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 165/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 1.0000\n",
      "Epoch 00165: val_loss did not improve from 0.08609\n",
      "80/80 [==============================] - 30s 377ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 166/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 1.0000\n",
      "Epoch 00166: val_loss did not improve from 0.08609\n",
      "80/80 [==============================] - 30s 375ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 167/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 1.0000\n",
      "Epoch 00167: val_loss improved from 0.08609 to 0.08592, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 378ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 168/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 1.0000\n",
      "Epoch 00168: val_loss did not improve from 0.08592\n",
      "80/80 [==============================] - 30s 385ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 169/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0588 - accuracy: 1.0000\n",
      "Epoch 00169: val_loss did not improve from 0.08592\n",
      "80/80 [==============================] - 30s 378ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 170/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 1.0000\n",
      "Epoch 00170: val_loss did not improve from 0.08592\n",
      "80/80 [==============================] - 30s 377ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 171/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 1.0000\n",
      "Epoch 00171: val_loss did not improve from 0.08592\n",
      "80/80 [==============================] - 30s 377ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 172/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 1.0000\n",
      "Epoch 00172: val_loss did not improve from 0.08592\n",
      "80/80 [==============================] - 30s 378ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 173/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 1.0000\n",
      "Epoch 00173: val_loss improved from 0.08592 to 0.08585, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 378ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 174/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 1.0000\n",
      "Epoch 00174: val_loss did not improve from 0.08585\n",
      "80/80 [==============================] - 30s 379ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 175/175\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 1.0000\n",
      "Epoch 00175: val_loss improved from 0.08585 to 0.08575, saving model to siamese_network2c-t3_20notebook.h5\n",
      "80/80 [==============================] - 30s 377ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9583 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA/ZklEQVR4nO3dd3zV9fX48dfJIgMSQtgJEKaMsAOCKIKDggPEBSgq1krVWu2wrV/111o7bGvrHhXrXmhRFCuKCwcCsvfeJGEGCAlJIOP8/nh/ApdwAwFyuTfJeT4e93Hv/ax77ke8J+8tqooxxhhTXliwAzDGGBOaLEEYY4zxyxKEMcYYvyxBGGOM8csShDHGGL8sQRhjjPHLEoQxQSQiy0VkULDjMMYfSxAmZInIdSIyT0TyRGSbiHwiIucG8PMGiUhGAK//ioj82XebqnZR1a+r+HNSRURFJKIqr2tqH0sQJiSJyK+Ax4G/Ak2AlsCzwIgghoX96JraxBKECTkikgA8BPxMVd9X1QOqWqSqH6nqb7xj6ojI4yKS5T0eF5E63r5BIpIhIr8WkZ1e6eNmn+tfIiIrRCRXRDJF5B4RiQM+AZp7JZY8EWkuIg+KyCQReUNE9gPjRKSviMwSkX3etZ8WkSjv2iIij3mfu19ElopImoiMB64Hfutd+yPv+E0icpH3WQUi0sAnzp4isltEIr33PxaRlSKyV0SmiUirU7i3zUVkiojsEZF1InKrz76+Xoltv4jsEJFHve3R3vfP9r7zXBFpcrKfbaofSxAmFPUHooHJxznmfqAf0APoDvQFHvDZ3xRIAJKBW4BnRCTR2/ci8FNVrQekAV+p6gFgGJClqnW9R5Z3/AhgElAfeBMoAX4JNPRivRC4wzt2CDAQ6OB9/rVAtqpO8M79h3fty32/jPdZs4CrfDZfB0xS1SIRGQHcB1wJNAK+A94+zv2pyEQgA2gOXA38VUQu8PY9ATyhqvFAW+Bdb/tN3ndpASQBtwEFp/DZppqxBGFCURKwW1WLj3PM9cBDqrpTVXcBfwRu8Nlf5O0vUtWpQB5wls++ziISr6p7VXXBCeKZpaofqGqpqhao6nxVna2qxaq6CXgeON/n2vWAjoCo6kpV3VbJ7/0WMAZcSQQY7W0D96P8sHe9YlzVW4+TKUWISAtgAPA7VS1U1UXAf4AbfWJvJyINVTVPVWf7bE8C2qlqiff991f2c031ZQnChKJsoOEJ6vubA5t93m/2th2+RrkEkw/U9V5fBVwCbBaRb0Sk/wni2er7RkQ6iMj/RGS7V+30V1xpAlX9CngaeAbYKSITRCT+BNcv8x7QX0Sa4UohpbiSAkAr4AmvimcfsAcQXAmpspoDe1Q112fbZp9r3IIr+azyqpEu87a/DkwDJnrVef8oq/YyNZslCBOKZgEHgSuOc0wW7kezTEtv2wmp6lxVHQE0Bj7gSFVKRVMbl9/+HLAKaO9Vx9yH+7Euu/6Tqtob6Iz7wf3NCa5fdt5e4DNgFK56aaIemW55K65arL7PI0ZVZ57wCx+RBTQQkXo+21oCmd7nr1XVMbj78ndgkojEeaWwP6pqZ+Ac4DKOlDpMDWYJwoQcVc0Bfo9rN7hCRGJFJFJEhonIP7zD3gYeEJFGItLQO/6NE11bRKJE5HoRSVDVImA/7i91gB1AktdIfjz1vPPyRKQjcLvP9fuIyNneX9gHgMJy129zgmu/hfvxvZoj1UsA/wb+T0S6eJ+TICLXnOBadbwG5mgRicYlgpnAw962brhSwxveNceKSCNVLQX2edcoFZHBItJVRMK9713k851MDWYJwoQkVf0X8Ctcw/Mu3F/Qd+L+4gf4MzAPWAIsBRZ42yrjBmCTVz10G649A1VdhUs8G7yqnOYVnH8P7i/8XOAF4B2fffHetr246pts4BFv34u4to99IvIB/k0B2gPbVXVx2UZVnYz7q36iF/cyXKP68eThGpPLHhfg2jhScaWJycAfVPUL7/ihwHIRycM1WI9W1QJcg/8kXHJYCXyDq3YyNZzYgkHGGGP8sRKEMcYYvyxBGGOM8csShDHGGL8sQRhjjPGrxkw81rBhQ01NTQ12GMYYU63Mnz9/t6o28revxiSI1NRU5s2bF+wwjDGmWhGRzRXtsyomY4wxflmCMMYY45clCGOMMX7VmDYIf4qKisjIyKCwsDDYodQY0dHRpKSkEBlpk3kaU9PV6ASRkZFBvXr1SE1NxU2vb06HqpKdnU1GRgatW7cOdjjGmACr0VVMhYWFJCUlWXKoIiJCUlKSlciMqSVqdIIALDlUMbufxtQeNT5BnFBpCezfBocOBDsSY4wJKZYgVCFve8ASxL59+3j22WdP+rxLLrmEffv2VX1AxhhTSZYgwsLdswZmgayKEkRxcbGfo4+YOnUq9evXD0hMxhhTGTW6F1OliICEuaqmALj33ntZv349PXr0IDIykujoaBITE1m1ahVr1qzhiiuuYOvWrRQWFnL33Xczfvx44MjUIXl5eQwbNoxzzz2XmTNnkpyczIcffkhMTExA4jXGmDK1JkH88aPlrMja73/noQMQthcitpzUNTs3j+cPl3c57jF/+9vfWLZsGYsWLeLrr7/m0ksvZdmyZYe7ib700ks0aNCAgoIC+vTpw1VXXUVSUtJR11i7di1vv/02L7zwAtdeey3vvfceY8eOPalYjTHmZNWaBHFcIsCZWXq1b9++R40hePLJJ5k8eTIAW7duZe3atcckiNatW9OjRw8AevfuzaZNm85IrMaY2q3WJIjj/qW/a7Vri0hqF/A44uLiDr/++uuv+eKLL5g1axaxsbEMGjTI7xiDOnXqHH4dHh5OQUFBwOM0xhhrpAavDSIwjdT16tUjNzfX776cnBwSExOJjY1l1apVzJ49OyAxGGPMqQhoghCRoSKyWkTWici9fvb/SkRWiMgSEflSRFr57LtJRNZ6j5sCGSdh4aCBaaROSkpiwIABpKWl8Zvf/OaofUOHDqW4uJhOnTpx77330q9fv4DEYIwxp0JUA1P3LiLhwBrgYiADmAuMUdUVPscMBn5Q1XwRuR0YpKqjRKQBMA9IxzUOzAd6q+reij4vPT1dyy8YtHLlSjp16nTiYPduhoO50DTtJL9l7VTp+2qMCXkiMl9V0/3tC2QJoi+wTlU3qOohYCIwwvcAVZ2uqvne29lAivf6R8DnqrrHSwqfA0MDFmlYeMDGQRhjTHUVyASRDGz1eZ/hbavILcAnJ3OuiIwXkXkiMm/Xrl2nHql4VUwBKk0ZY0x1FBKN1CIyFled9MjJnKeqE1Q1XVXTGzXyu+Z25YR5t8FKEcYYc1ggE0Qm0MLnfYq37SgichFwPzBcVQ+ezLlVRsqm2whMQ7UxxlRHgUwQc4H2ItJaRKKA0cAU3wNEpCfwPC457PTZNQ0YIiKJIpIIDPG2BUbZfEwBmm7DGGOqo4ANlFPVYhG5E/fDHg68pKrLReQhYJ6qTsFVKdUF/uutM7BFVYer6h4R+RMuyQA8pKp7AhXrkRKEVTEZY0yZgLZBqOpUVe2gqm1V9S/ett97yQFVvUhVm6hqD+8x3Ofcl1S1nfd4OZBxIt5tCIESRN26dQHIysri6quv9nvMoEGDKN+lt7zHH3+c/Pz8w+9t+nBjzMkKiUbqoAsLvTaI5s2bM2nSpFM+v3yCsOnDjTEnyxIEHKliCkAJ4t577+WZZ545/P7BBx/kz3/+MxdeeCG9evWia9eufPjhh8ect2nTJtLS3MC9goICRo8eTadOnRg5cuRRczHdfvvtpKen06VLF/7whz8AbgLArKwsBg8ezODBgwE3ffju3bsBePTRR0lLSyMtLY3HH3/88Od16tSJW2+9lS5dujBkyBCb88mYWq7WTNbHJ/fC9qUV7FQ4lAfhdSA8qvLXbNoVhv3tuIeMGjWKX/ziF/zsZz8D4N1332XatGncddddxMfHs3v3bvr168fw4cMrXO/5ueeeIzY2lpUrV7JkyRJ69ep1eN9f/vIXGjRoQElJCRdeeCFLlizhrrvu4tFHH2X69Ok0bNjwqGvNnz+fl19+mR9++AFV5eyzz+b8888nMTHRphU3xhzFShBHqfqBcj179mTnzp1kZWWxePFiEhMTadq0Kffddx/dunXjoosuIjMzkx07dlR4jW+//fbwD3W3bt3o1q3b4X3vvvsuvXr1omfPnixfvpwVK1ZUdBkAZsyYwciRI4mLi6Nu3bpceeWVfPfdd4BNK26MOVrtKUGc4C99ti2G2CRISDn+cafgmmuuYdKkSWzfvp1Ro0bx5ptvsmvXLubPn09kZCSpqal+p/k+kY0bN/LPf/6TuXPnkpiYyLhx407pOmVsWnFjjC8rQZSRwM3oOmrUKCZOnMikSZO45ppryMnJoXHjxkRGRjJ9+nQ2b9583PMHDhzIW2+9BcCyZctYsmQJAPv37ycuLo6EhAR27NjBJ598cviciqYZP++88/jggw/Iz8/nwIEDTJ48mfPOO68Kv60xpqaoPSWIEwkLD9iaEF26dCE3N5fk5GSaNWvG9ddfz+WXX07Xrl1JT0+nY8eOxz3/9ttv5+abb6ZTp0506tSJ3r17A9C9e3d69uxJx44dadGiBQMGDDh8zvjx4xk6dCjNmzdn+vTph7f36tWLcePG0bdvXwB+8pOf0LNnT6tOMsYcI2DTfZ9ppzXdN5zRVeWqO5vu25iaI1jTfVcvYeEhMVDOGGNChSWIMmJrQhhjjK8anyAqXYVmJYhKqSlVksaYE6vRCSI6Oprs7OzK/ahJWEhNtRGKVJXs7Gyio6ODHYox5gyo0b2YUlJSyMjIoFKrzRXmuMfeSKhgRLNxSTclperHihhjQk+NThCRkZG0bt26cgfPegam3Qe/2wwx9QMalzHGVAc1uorppNSp554PHju4zBhjaiNLEGWiE9xzYU5w4zDGmBBhCaJMTKJ7Ltgb3DiMMSZEWIIoczhBBG5lU2OMqU4CmiBEZKiIrBaRdSJyr5/9A0VkgYgUi8jV5fb9Q0SWi8hKEXlSKlosoarENHDP+ZYgjDEGApggRCQceAYYBnQGxohI53KHbQHGAW+VO/ccYADQDUgD+gDnBypWAGK9BGFVTMYYAwS2m2tfYJ2qbgAQkYnACODwijaqusnbV36OCwWigShAgEig4hV1qkJkDEREWxWTMcZ4AlnFlAxs9Xmf4W07IVWdBUwHtnmPaaq6svxxIjJeROaJyLxKDYY7kZgGkG8lCGOMgRBtpBaRdkAnIAWXVC4QkWNWtVHVCaqarqrpjRo1Ov0Pjm1gVUzGGOMJZILIBFr4vE/xtlXGSGC2quapah7wCdC/iuM7VkyiVTEZY4wnkAliLtBeRFqLSBQwGphSyXO3AOeLSISIROIaqI+pYqpyMYnWi8kYYzwBSxCqWgzcCUzD/bi/q6rLReQhERkOICJ9RCQDuAZ4XkSWe6dPAtYDS4HFwGJV/ShQsR5mVUzGGHNYQCfrU9WpwNRy237v83ouruqp/HklwE8DGZtfZVVMqjajqzGm1gvJRuqgiWkApcU2YZ8xxmAJ4mg2WM4YYw6zBOHL5mMyxpjDLEH4svmYjDHmMEsQvqyKyRhjDrME4cvWhDDGmMMsQfgqSxBWxWSMMZYgjhIeCXXirZHaGGOwBHGsmPpWxWSMMViCOFZMA6tiMsYYLEEcK7aBVTEZYwyWII4VYxP2GWMMWII4VmwDOJAd7CiMMSboLEGUF9cYDuZA8cFgR2KMMUFlCaK8ut7SpQeqYI1rY4ypxixBlBfX2D3n7QxuHMYYE2SWIMqr6yUIK0EYY2q5gCYIERkqIqtFZJ2I3Otn/0ARWSAixSJydbl9LUXkMxFZKSIrRCQ1EDGWlCpb9+STk1/kNsR5VUxWgjDG1HIBSxAiEg48AwwDOgNjRKRzucO2AOOAt/xc4jXgEVXtBPQFAvKLnZ13kPP+MZ0pS7LchrISRN6OQHycMcZUG4Fck7ovsE5VNwCIyERgBLCi7ABV3eTtK/U90UskEar6uXdcXqCCrB8bBcC+A4fchsgYiKpnVUzGmFovkFVMycBWn/cZ3rbK6ADsE5H3RWShiDzilUiOIiLjRWSeiMzbtevUftCjIsKoWyeCPfmHjmys28iqmIwxtV6oNlJHAOcB9wB9gDa4qqijqOoEVU1X1fRGjRqd8ofVj41kX1kbBLieTFaCMMbUcoFMEJlAC5/3Kd62ysgAFqnqBlUtBj4AelVteEckxkax10oQxhhzlEAmiLlAexFpLSJRwGhgykmcW19EyooFF+DTdlHVEuOi2HtMCcIShDGmdgtYgvD+8r8TmAasBN5V1eUi8pCIDAcQkT4ikgFcAzwvIsu9c0tw1UtfishSQIAXAhVrYmwkew/4liAauwn7SooqPskYY2q4QPZiQlWnAlPLbfu9z+u5uKonf+d+DnQLZHxljqliivOZbiO++ZkIwRhjQk6oNlKfUfVjI8ktLKa4xOttW9em2zDGGEsQQIM4byxEQdloaj/Tbaie4aiMMSa4LEFwZLDc4XaIuuWm29j4Lfy1Oezb6udsY4ypmSxB4BqpgSM9mQ6XILwEsfpTKMqHDV+f+eCMMSZILEHgGqmBIw3VdepCZCzkeVVMW2Z6z7ODEJ0xxgSHJQjcOAjg2K6uOVvhYB5sW+K2lSUKY4ypBSxB4KeKCaDNIFj7Oaz7HLQE2gyGPRsg12Z5NcbUDpYggJjIcKIiwtjnOxYi/RYoLoBp94OEwYC73XYrRRhjaglLEICI0KD8YLlm3SClD+zPhKZdIfVciIixdghjTK1hCcJTPzaSPQfKTa2Rfot7bnkOhEdCSjpsmmFjIowxtYIlCE9ibNTRVUwAXUZC2lXQY4x732k47FgGq6ceewFjjKlhLEF4GsSVq2ICiIyGq1+CZt3d+/SboVEn+OReOJQPRQWwdQ6smAKlpcde1BhjqrGATtZXnRyzaJA/4ZFw6T/hlUvhsS5uxle86qbB98P5vw14nMYYc6ZYgvCUzehaWqqEhUnFB6aeCxf+HnauggatXQP28g9g+l+haTc4a+gZi9kYYwLJEoSnfmwkpQq5hcUkeOMiKnTer49+3+4iyF4LH9wGdy+G0hKYeB0M+j9oc37ggjbGmACyNghP2Yyue8q3Q1RGZAxc/oSrcpr9HHz9N9gyCz7/f9bjyRhTbVmC8DSJjwZge07hqV2geU/odDnMfArm/gcatIFti91obICcTFjwGmQtqpqAjTEmwKyKyZNcPwaAzH0Fp36RQffByv9BnXgYNxVevBg+ewC+fQQy5rhjYhJh/DeQ2KoKojbGmMAJaAlCRIaKyGoRWSci9/rZP1BEFohIsYhc7Wd/vIhkiMjTgYwToFn9aEQgY2/+qV+kSWe47FG4+kWIbwYD74Hdq6EwBy78A4x933WHfWes6yJrjDEhLGAlCBEJB54BLgYygLkiMkVVV/gctgUYB9xTwWX+BHwbqBh91YkIp3G9OmTuPc0f7vQfH3nd6yZofT4kpoJ4PaOuegHeuhY++R0Mf9Jt27Ecvvm7mxAw/ebT+3xjjKkigaxi6gusU9UNACIyERgBHE4QqrrJ23fMKDMR6Q00AT4F0gMY52EpibFknG6C8CXiusL66vAjGPAL+P5xNwBv+xLXNqGlkDHfJZUwaxoyxgRfIH+JkgHfNTozvG0nJCJhwL+ouGRRdtx4EZknIvN27dp1vEMrJbl+zOm1QVTWBQ9Acjp8/CtY+Ab0/Sn86GHYnwFZC9wxJ+r9pGo9pIwxARWqf6reAUxV1YzjHaSqE1Q1XVXTGzVqdNofmpIYQ9a+AkpKA/zDGx4J174K59wFd/wAw/4GPa6DsEhY8QGs+BAeS4Otcyu+xpd/hAmDAhunMaZWC2QVUybQwud9iretMvoD54nIHUBdIEpE8lT1mIbuqpScGENxqbIzt5BmCTGB/ChISIEhfzryPqY+tB0MSyfB/NfgYA68PQpu+RyS2h59bkmRq5bKz4a8nW71O2OMqWKVKkGIyN1ejyIRkRe9nkdDTnDaXKC9iLQWkShgNDClMp+nqteraktVTcVVM70W6OQAR7q6Vmk7xMnoPAJyt7kV7K5/z1UhvT4Sdq89+rgN37jkAJA5/8zHaYypFSpbxfRjVd0PDAESgRuAvx3vBFUtBu4EpgErgXdVdbmIPCQiwwFEpI+IZADXAM+LyPJT/B5VIiUxFuD0ezKdqo6XQmJruOwxaH8RjJ0ERfnwnwth/fQjxy2b5MZaSLglCGNMwFS2iqls9rpLgNe9H/rjzGjnqOpUYGq5bb/3eT0XV/V0vGu8ArxSyThPy5ESxGmMhTgdMYlw9yKfgHrDT76At0a7ksS5v4Buo91gvM4j3Ehtfwli91rYu9klGWOMOUWVLUHMF5HPcAlimojUA2rcAggxUeE0rBt1ZnoyVVZiKtz6JfS6AWY8Bs+eDYdyoetVkNzLJYjyvZmm3QcTx3jTkRtjzKmpbAniFqAHsEFV80WkAVAjR3Ql148JXhtERaLiYPhTbhDezlVQcghaD4KcDFjwKmSvh4bt3LFFhbDxO3fMsvehzy3BjNwYU41VNkH0Bxap6gERGQv0Ap4IXFjBk5IYy4pt+4Mdhn/Ne7pHmeTe7nnBq246j3N+Dvu2QHEBRETD4rctQRhjTlllq5ieA/JFpDvwa2A98FrAogqiNo3i2LInn/xDxcEO5cQadYTIOJj5pEsSn/wO1n0J4XXcmhUZc4/0gCrY50oUpSVBDdkYU31UNkEUq6ripsp4WlWfAeoFLqzg6dmyPiWlyuKtOcEO5cTCwmHoX2HIn93iROu/hEVvQOoA6HUjSBh8+084mOfmf5p0M8yZEOyojTHVRGWrmHJF5P9w3VvP86bCOMGya9VTzxaJACzYspf+bZOCHE0l9B7nng/lw7yXIG8HtLsY6jWF/ne60sXaaa4E0agTfPFHNx9UgzbBjNoYUw1UtgQxCjiIGw+xHdc19ZGARRVEiXFRtGkUx4LN1awHUFQsDLrXjY3o8CO3bcifYOQEQGDowzD2PTfNxwd3uNHYxhhzHJVKEF5SeBNIEJHLgEJVrZFtEAC9WyaycOs+tLpNhtf7Zvj1qqOn5ug+Cn67AfrdDgnJcOm/3HKon/zOrUmx4RsoPoVlVo0xNV5lp9q4FpiDG/F8LfCDvwV+aoperRLZc+AQm7KDNGDuVIn4n5fJd0xjt2vdJIHzXoR/tIHXhrupx8sc2A1vXAX/+xUUHwx4yMaY0FXZNoj7gT6quhNARBoBXwCTAhVYMPVq6doh5m/eS+uGcUGOJgAuetBN4VFUCLtWubaLc38JOVtdcsjJcOModq6A0W9BbINgR2yMCYLKtkGElSUHT/ZJnFvttG9cl3p1Ipi7cU+wQwmMsHBX1XTFMzDwN26CwEVvwutXusbscR/D1S+5brJf/TnY0RpjgqSyP/Kfisg0ERknIuOAjyk3x1JNEhYmXNylCR8tyWLvgRpeP9/+YqjfCj76hSs5jHkbWvSFtKvc6nYLXoU9G4MdpTEmCCrbSP0bYALQzXtMUNXfBTKwYLvt/LbkHyrhlZmbgh1KYIWFQ9/xgMKwv0PLfkf2DfyNW8To64fd++KD8Pz5MO3+yl9/xYcw/eEqDdkYc2ZUesEgVX0PeC+AsYSUDk3qMaRzE16ZuYlbB7ahbp1Arq0UZP3ugDaDoEmXo7fHN4Ozx8P3T0LnK2D7Uti2yI3OPv93EB3vJgpc/6V7bn/xsdf+6i+wZz0MuMvNKWWMqTaOW4IQkVwR2e/nkSsiITphUdW5Y3A7cgqKeGDy0sAvQxpMYWHQNO3o3k5lBv7Wzf/033Hw3T/d66IDsPRdlzCe7e8att8efezCRjtXwu7VUFps61YYUw0dN0Goaj1VjffzqKeq8WcqyGDp0aI+9wzpwAeLsrh74kIKi2rhPEZ16roBdg1aQ2QMjHkHmnWH2c+5xFCY4xY4ioiBz38P+Xvgm0fcpIHLJ7vpPhDYPCvY38QYc5JqcL1J1bjzgvZEhofx8CerWL09l8dG9SAtOSHYYZ1ZsQ3g1q+gcD/Ua+KmHf/obqiTALdMg8adXKL44kF4qpdbh2Lpu67k0GqAe7/FJ0HsXAmznoFLHnFJxxgTkgLaVVVEhorIahFZJyLHrCktIgO99a2LfQfeiUgPEZklIstFZImIjApknCfy0/Pb8tqP+5JbWMwVz3zPU1+upbikxq2XdHxRca5NAqDrNdB9DFz3jksOAGffDkntoV5zV6LYsxH2bIAuV0DL/q7LbEmxm+Lj/Vth4euwrNY0aRlTLUmgppMQkXBgDXAxkAHMBcao6gqfY1KBeOAeYIqqTvK2dwBUVdeKSHNgPtBJVfdV9Hnp6ek6b968gHyXMjn5Rfx+yjI+XJRFx6b1+M2PzuKCjo2pxOqrtUPxITfXkwgsfgdmPQU3fAAbvob3boHxX8P6r+DLhyA6ARq0hfHTT3BRY0wgich8VU33ty+QJYi+wDpV3aCqh4CJuOnCD1PVTaq6hHLLl6rqGlVd673OAnYCjQIYa6UkxEbyxOie/HtsLwqKSrjl1Xlc+/ws5m6qoQPqTlZE1JGG7u6j4LYZENfQlSDATRI4/a9uPe3B90PWAshaGLx4jTHHFcgEkQxs9Xmf4W07KSLSF4jCLVJUft94EZknIvN27dp1yoGerKFpzfjiV+fz5yvS2JSdzzX/nsUtr8xlZaiuRBdsCcnQuAvsz3LtF5c9Dt1HQ2Qs/GDrUxgTqkK6kVpEmgGvAzep6jGV/qo6ATeAj/T09DPaDzUyPIyx/VpxZa9kXpm5iee+Xs+wJ75jaJem/PzCdnRpXssask/k1i9dj6aIOke29bwB5jzvutkmp8PGb+D8e6Fxx+DFaYw5LJAJIhNo4fM+xdtWKSISj5vS435VnV3FsVWZ2KgI7hjUjuv6tuSlGRt5+ftNfLp8Oxd3bsLdF7avfT2eKuKvt9KP/uq60X73KCx8AxA3m+xNHx2pqtqxAuo2gbhqsHiTMTVMIBupI3CN1BfiEsNc4DpVXe7n2FeA//k0UkcBnwAfqerjlfm8M9FIXRk5BUW88v0mXpyxgf2FxVzStSm/vKgD7ZvUyBVaq8aO5W6t7C2z4ZPfwJiJcNYw2LUG/n2uG5z340/9D+QzxpyW4zVSByxBeB98CfA4EA68pKp/EZGHgHmqOkVE+gCTgUSgENiuql1EZCzwMuCbTMap6qKKPitUEkSZnIIiXpyxkZdmbOTAoWKGd2/OnYPbWaI4npIieLYfIK4L7eTbIGOO2zfuY0g9N6jhGVMTBS1BnEmhliDK7D1wiOe/3cBrszZRUFTCJWnNuPOCdnRqVuMHop+adV/A22PcehQAlz/hphxvkgY3fnDkOFU3iWByOnQYEpRQjakJLEGEgD0HDvHijA28OnMzeQeLGdK5CXdZG4V/+7fB7Gfd64sfgu+fgC/+AK3Pd+0Rg/8PVkxx2xp3gTtmBjdeY6oxSxAhJCe/iJe+38jL329kf2ExF3RszM8vaEdPbxU748fBXHh/PBzYBbtWg5a6FfFiG8KBnXDnPGjYPthRGlMtBWugnPEjITaSX17cgRn3XsA9QzqwYMteRj47kxte/MEG3FWkTj23kNFPvoDbZ0JKuqtyGvex27/ig6OPLyqECYPdiG1feTuPnXHWGFMhK0EEWd7BYt6YvZkXvt1A9oFD9G+TxF0XtqdfmwY2hcfxqLpeTS8OgUP5cPuMI/u++jN8+whExsGvV7ppPQBevdx1m/31KjcliDHGShChrG6dCG47vy0zfncBD1zaiXW78hjzwmyufX4W367ZRU1J4FWuLHl2HgE7lsLaz13JYeO3MOMxaNHPrVux8A133I4Vbl/+bjc3lDHmhCxBhIiYqHB+cl4bvvvtYP44vAsZewu48aU5jHx2Jl+t2mGJoiJdRkJ0fXjzavhLE1dKiK4Po99yc0DNmeDGWMyZAOF13BTlS/9buWsX7nczztq9N7WUVTGFqIPFJUyan8Gz09eTua+AtOR4fn5Bey7u1ISwMKt6OkrBXlg/3a0z0bA9tB4I9Zq6BYv+Ow46DXfdZ7tc6dbgXvYe3LMWomKPf90Zj7k1Lm773q24Z0wNdLwqppCei6k2qxMRzvVnt+La9BZMXpDJM1+v46evz6dj03r8/IL2DEtraomiTEwipF157PaOl8OAu2Hey1BU4NbXLsyBBa/Cf2+CvZvc1B6xSXDDZKjf4ujzy1bB2zzTEoSplawEUU0Ul5Ty0ZIsnvpqHRt2HaBd47r8/IJ2XNatOeGWKI7vYJ5bArVJZ1fd9GRPyNvhShr1W8Kit6DNINdTan+Wa9SOiIF/pLqE0mUkXPNKkL+EMYFh4yBqkJJS5eOl23j6q7Ws2ZFH64Zx/GxwO0b0aE5kuDUpVUrhflfVFBXn3s943A266zwCVn3sqqTO+zX8ewBE1XPH/XqVzQVlaiTrxVSDhIcJw7s359O7B/Lc9b2Ijgznnv8u5oJ/fc3EOVs4VFzLlkI9FdHxR5IDQP+fuRHZKz6E+q3cc9lyqH1ugbztbvlUY2oZK0FUc6rKFyt38tRXa1mSkUPzhGiu79eKUX1a0LBunRNfwDj7t7lR2dEJ8EQPV8KIaww3vO8mEBzxDPQcG+wojaly1khdg4kIF3duwkWdGvPNml08/80GHpm2mqe/Wsct57Zm/PltiI+2QWEnFN/MPQA6DIU1n0DLftCoI8Q0gGXvu5HYWQvcaOwRz7gR3cbUYFbFVEOICIPOaszb4/vxxa8GcnHnJjw9fR0DHv6Kh6euZHtOYbBDrD763uqeW53j2h1Sz4X1X8KXf3RrV+RkuAkEjanhrIqpBluWmcPz327g4yVZXttFMuMHtuGsprYmxXGpwtrP3OyxkdGQuwN2rYJm3VyX2s8egNnPwS+Xw/alsORdKC121VOJqZB+85HpPYwJcdaLqZbbuiefF2ds5J25WykoKmHwWY0YP7Ctzfd0qrLXw1O9oNPlsPpTlwyiE6BwH+Rnu8Qy9j2b78lUC5YgDOAWL3p99mZenbmJ7AOH6J6SwPiBbRma1tTGUpysV4fDxm8gqZ2bZTbGm6590Vvwwe3Q51a45BFXRVVS7Bq9LRmbEGSN1AaAxLgo7rqwPeMHtmHS/Az+890GfvbWAlolxXLreW24uncK0ZHhwQ6zehj4GzeI7uqXjiQHgB7Xwc4VMPMpN035WcPg3RshubcbbGelClONBHpN6qHAE7g1qf+jqn8rt38gbs3qbsBoVZ3ks+8m4AHv7Z9V9dXjfZaVIE5eSany2fLt/Pub9SzOyKFh3ShuHtCasf1akRBjP2SnrLQUPv4VzH8ZEIhr5LrQdhsFI56FcPu7zISOoFQxiUg4sAa4GMgA5gJjVHWFzzGpQDxwDzClLEGISANgHpAOKDAf6K2qeyv6PEsQp05Vmb1hD//+Zj3frNlF3ToRXNkrmZE9k+nRor61U5wKVbdg0Z71cNnjMO8l+OpPUK859L4JBvzCNYAbE2TBqmLqC6xT1Q1eEBOBEcDhBKGqm7x95Yf//gj4XFX3ePs/B4YCbwcw3lpLROjfNon+bZNYkbWfCd+u5525W3lt1mb6pjbgd8POonerBsEOs3oRgYv+cOT9eb+Gxp1dovj6YVg9FS5/AuJTIK6hO760FLLXQnwy1KkbvNiN8QQyQSQDW33eZwBnn8a5yeUPEpHxwHiAli1bnlqU5iidm8fz+OiePFRYxOQFmTz11Tquem4WZ7duwPiBbRh8VmObRfZUiEDHS9xj1VSYfBtMGOT2dRgKV06AD38GKz9y21r0g+FPQqOzghayMdV6oJyqTlDVdFVNb9SoUbDDqVHioyO56ZxUvv3tIB64tBNb9+Rzy6vzuPixb5g4ZwuFRSXBDrH66ngJ/Gw2XPmCa+xe+xk81tUlh3N/BYPug91r4PmBMOsZV7JY8xl8eh+UFAU7elOLBLIEkQn4TrCf4m2r7LmDyp37dZVEZU5KbFQEPzmvDTedk8rUpduY8O0G7n1/Kf/8bDU39U9lbL9WJMZFBTvM6ie+OXS71r1u1h0+vBN+9DD0v8Nt6z0OProbpt0Hc16AvRvd9lb93fgLY86AQDZSR+AaqS/E/eDPBa5T1eV+jn0F+F+5Rur5QC/vkAW4Ruo9FX2eNVKfGarKrPXZTPhuA1+v3kV0ZBgje6Zw84BUOjSxEdqnTPXYcRKqsOhNmP4wdB/t1tdu3hOum+j2Fx+CxW9B2wvcuhbGnIKgNFKrarGI3AlMw3VzfUlVl4vIQ8A8VZ0iIn2AyUAicLmI/FFVu6jqHhH5Ey6pADx0vORgzhwR4Zx2DTmnXUPW7Mjlxe828v6CDN6es4UB7ZK4+ZzWDO7Y2AbenSx/PcVE3AyyZbPIagl8/yTkbner4E26GVb9z621ffZ46H4dNO5kA/JMlbGR1Oa07TlwiLfnbOH1WZvZvr+QVkmx3Ng/lWvSU2wm2aq0ex083Ru6j4HcbbDhaxj8AGSvgyXvAArth8CYdyDMp3mxtPTo98b4sKk2zBlRVFLKtOXbefn7TczfvJfYqHCu7p3Cjf1TadfYum1WiZeGwZaZEF0fLnjgyMyzuTtgzgT47p9wxXNuRDfAwjfdeIybp0JS26CFbUKXJQhzxi3NyOGVmZv4aHEWh0pK6ZOayE3npHJJWjPrJns6cjLcZIGtzjl22o7SUnhpCOzdBD+f79ownuwJBXsg9Ty46aOjq5/2bXEz0Z77Kyth1GKWIEzQ7M47yHvzXRvFpux8Ojatx0/Oa8Nl3ZrZvE+BkLUQJgx2a1gkpMDiidB3PMx53lVHdb0KElu7RPHBHa4R/MfT3OJIplayBGGCrqRU+d+SLJ76ah3rduZRPzaSUektuP7sVrRMig12eDXL/FfdmhUH90OPsTDiaXh9JGyY7vb3HQ+D74d/dYTiAjjn5zDkz8GN2QSNJQgTMsq6yb4+ezOfrdhBqSqDOjTixv6pDOzQyHo/VZXcHbD4beh1I8Q2cF1isxbC/Fdc19iu18DS/7oFjiQMfr7ALXqkpRBha5nXJpYgTEjallPA23O28vacLezKPUiLBjGMPbsV16a3sMF3gXLoADxzNuRsdWMqeo6Fj38N178HH93lutA27OAawDtd5s4pKYaZT7o1uFsPDG78pspZgjAh7VBxKZ+t2M5rszYzZ+MeoiLCuLxbc27o34oeLeoHO7yaZ9VUmDgGhj8N7S6ERztBWCRExkD6j2Ht57BzOfT5CXQa7qb7WDsNImLgpinQom+wv4GpQpYgTLWxensur8/exOQFmRw4VEK3lATG9mvF8O7NrVG7Ku1e61bDE4EXLnDVT9f9F9pfBMUHYdr9MPcFd6yEwUUPuuqpgr1uSpD2F8OW2bA/yy2M1PJsaNAmmN/InCJLEKbayS0sYvLCTF6ftZm1O/NIiInk2vQUxvZrRaukuGCHV7PsXAl5O6DNoKO3H8iGzPlQr4mbL2rPRnh7NOxa5f86Lc52a3If2O0SSIehborzjd/Cmk/grEvcHFPhUW7SQS2BLbNg8yxXrdWkM+TtdCv0NetuI8LPEEsQptoqW8zojdmb+XT5dkpKlfM7NOLG/q0YdJZN6XHGqbq1uDPmQsv+0PAsN85ixRRY9ZFb3yI6AdZ86raXiU+B/RmumqrkkEsOx9OsOzTr4dbyPpTvjk9IcQMESw5BRLRrfG/SBRq0dSWZfVsgZ4tbT6Nlf4ip7z/+/Gw3Er3kEDTtVuuXgbUEYWqEHfsLeeuHLbw9Zws7cw+SkhjD9We34tr0FJLqWs+bkFJSDLtWwvZl0KgDNO/lutmu/tRVSUVGA+JKGK0HuulCstdBvaauhLLwDfejX1oMkXGuNLE/072vrIQWbrnX3O2ucT480q0jXuozZXpkHDTv4Y5NSHGz7EbFuWPDo+BgnmvQD4tw81+hrvRTcsglq+Y93ZodYT7VnweyoXCfq3ITcUkpe71LkK0GhFxCsgRhapSiklI+W76D12dvYvaGPUSFh3FZt2aM7d+KnrZEas1VWgJFBa70UFzgqqOyFrof8PgUSGzlSg97N7mqq91r3DH1mrmkVHLIlW7qNXOJCIVNM2DHcjdCfX/WiUs2/kTGuRJPk85QVAhL33WfFZsEsQ3hUJ5LbgB1m7qEtD/TfRfEtQU1TYMmaa5ks2KKKx21GeSq28IjvU4E0RBV1z2K8t3qhLtWuXEtXa85OkmdBEsQpsZasyOXN2Zv5v0FmeQdLCYtOZ4b+rViePdkYqKsUduchJJiOLATiguPlBIiY13JorTEVU1JmCtZhEd6CWoBZC6AbYtcW07JITcPVtNukDnPlUDCI137TN3Gbm6s/ZlHlpUtKXKJbPfaI8mpSZor6eRsPW64RMa662SvhZS+cMtnp9RuYwnC1Hh5B4u9Ru1NrNnhGrWv6Z3C9f1a0bqhNWqbM0DVVYGdShVSUaGrkouMc1Vyqq5UU5TvkkhpkTvm0AFXIiktduuARNeHlVNclVbvcacUtiUIU2uoKnM27uG12ZuZtmw7xaXKgHZJjO7TkiFdmlAnwkoVxvgKyoJBxgSDiHB2myTObpPEzv2FTJy7lXfmbuXnby8kMTaSq3qlMLpvS5t+3JhKsBKEqfFKS5UZ63Yzce4WPlu+g+JSpW/rBlzXtyVD05raADxTqwWtiklEhgJP4JYc/Y+q/q3c/jrAa0BvIBsYpaqbRCQS+A9uTeoI4DVVffh4n2UJwlTGrtyDTJqfwcS5W9icnU99r1Qxpm8L2jW2NbVN7ROUBCEi4cAa4GIgA7e+9BhVXeFzzB1AN1W9TURGAyNVdZSIXAcMV9XRIhILrAAGqeqmij7PEoQ5GaWlyqwN2bw1ZwufLd9OUYnSN7UBY85uwbA0W6vC1B7BaoPoC6xT1Q1eEBOBEbgf+zIjgAe915OAp8V1YlcgTkQigBjgELA/gLGaWiYsTBjQriED2jU8alGjX76zmD98uJwreiZzbXoL0pITgh2qMUETyASRDPh25M0Azq7oGFUtFpEcIAmXLEYA24BY4JequqfcuYjIeGA8QMuWLas6flNLNKxbh5+e35bxA9swa0M278zdysS5W3lt1ma6NI9nVJ8WjOieTEJsaI2ANSbQQrUXU1+gBGgOJALficgXZaWRMqo6AZgArorpjEdpahQR4Zy2DTmnbUMeyi/iw8WZTJyzld9/uJy/fLySYWlNubZPC/q1TrJ1tU2tEMgEkQm08Hmf4m3zd0yGV52UgGusvg74VFWLgJ0i8j2QDmzAmDMgITaSG/uncmP/VJZl5vDO3K18sCiTDxZl0bJBLNf0TuGq3ik0rx8T7FCNCZiwAF57LtBeRFqLSBQwGphS7pgpwE3e66uBr9S1mm8BLgAQkTigH1DBHMPGBFZacgJ/uiKNOfddxGOjutO8fjT/+nwNA/7+FTe8+AMfLsqksOgU5vAxJsQFupvrJcDjuG6uL6nqX0TkIWCeqk4RkWjgdaAnsAcYraobRKQu8DLQGRDgZVV95HifZb2YzJm0JTufSQsyeG9+Bpn7CoiPjuCy7s0Z2TOZ3i0TrQrKVBs21YYxAVLWXfa/87YybfkOCopKSEmM4YoeyVzRM9lGbJuQZwnCmDPgwMFiPluxnckLs5ixdhelCl2TExjZM5nLuzenUT1bs8KEHksQxpxhO3ML+WjxNj5YmMnSzBzCw4Rz2zVkZM9khnRpQmxUqHYgNLWNJQhjgmjtjlzXA2phFpn7CoiNCudHXZpyRc9kBrRNIiI8kH1FjDk+SxDGhIDSUmXe5r1MXpjJx0uy2F9YTMO6dRjuNW6nJcfbanjmjLMEYUyIOVhcwvRVu/hgYSZfrdrJoZJS2jaKY2TPZEb0SKZFg9hgh2hqCUsQxoSwnPwipi7bxuSFmczZ6GaU6ZOayBU9k7m0azPqx0YFOUJTk1mCMKaayNibz4eLspi8MJN1O/OIDBcGn9WYK3slM+isxjbLrKlyliCMqWZUleVZ+5m8MJMpi7PYlXuQ+OgILu3WjCt6JNMntYENxjNVwhKEMdVYcUkpM9dn88HCTD5dvp38QyUk149hRI/mXNEzmQ5NbKEjc+osQRhTQ+QfKubzFTuYvDCT79bupqRU6di0Hpd2bcZl3ZvTumFcsEM01YwlCGNqoF25B/l4SRb/W7KNeZv3AtC5WTyXdW/GZV2b0zLJekKZE7MEYUwNty2ngI+XbOPjpdtYuGUfAN1SEri0azMu6drMus2aClmCMKYWydibz9Sl2/h4yTYWZ+QA0KNFfS7r5pKFrWFhfFmCMKaW2ronn/8t2cbHS7NYlumWde/dKvFwsmgSHx3kCE2wWYIwxrBx9wGmLt3G/5ZsY+W2/YhAn1YNuKx7M4amNaVxPUsWtZElCGPMUdbtzDtcDbV6R+7hZDE0rSlD05paNVQtYgnCGFOhtTtymbp0O58s28aq7bkAdG9Rn2FpTRmW1pRWSdZ1tiazBGGMqZSNuw/wybJtfLpsO0u8Bu5OzeIZ0rkJ57VvSFpygk33UcMELUGIyFDgCdya1P9R1b+V218HeA3oDWQDo1R1k7evG/A8EA+UAn1UtbCiz7IEYUzV2ronn2nLtzNt+Xbmbd6LKoSHCfVjIokve0RHEB8TSUJMJPHR3nNMxOH3R/a54yJt7YuQE5QEISLhwBrgYiADmAuMUdUVPsfcAXRT1dtEZDQwUlVHiUgEsAC4QVUXi0gSsE9VSyr6PEsQxgROdt5B5m/ey7LMHLIPHGJ/YTE5BUXsL3sUFpFTUERRyfF/T2Kjwn2Sx9GJxDeZJMREEhsVQZ3IMOpEhBEdGU6diDDqRIQTHeme60SE2XxUVeB4CSKQ6x72Bdap6gYviInACGCFzzEjgAe915OAp8WtmDIEWKKqiwFUNTuAcRpjTiCpbh2GdGnKkC5NKzxGVSksKj2cLPYXeM+FReTkFx2VVMq2Z+0rZGVBLvsLi8gtLD7puKLCXQKpU5ZAIsOIjgg/YWKJ9j3e3zEnODYqPKxWLO4UyASRDGz1eZ8BnF3RMapaLCI5QBLQAVARmQY0Aiaq6j/Kf4CIjAfGA7Rs2bLKv4AxpvJEhJiocGKiwk9pfEVJqZLnJZGcgiIKiko4WFzCwaJSCr3ng8WlFBaVcLC4lIPFJRQWueejth9+LmXPgUPeecceW3oalSciHE4qxyQRnwTjNyn5JLQj54UT7W+7n2PO5BK1obpyegRwLtAHyAe+9IpBX/oepKoTgAngqpjOeJTGmCoTHiYkxEaSEBsZ8M9SVYpL9ZjE4jfh+E0+Rx9T/tjColJyCoqOXK/o6GNOR3iYHJNEuqbU56kxPavo7hwRyASRCbTweZ/ibfN3TIbX7pCAa6zOAL5V1d0AIjIV6AV8iTHGnCYRITJciAwPo26dM/t3sqoeThQHD5eMSo5KJhWWlCooTaUkBmbcSiDvzFygvYi0xiWC0cB15Y6ZAtwEzAKuBr5S1bKqpd+KSCxwCDgfeCyAsRpjzBkhIkRHhnvdhQNfWjodAUsQXpvCncA0XDfXl1R1uYg8BMxT1SnAi8DrIrIO2INLIqjqXhF5FJdkFJiqqh8HKlZjjDHHsoFyxhhTix2vm6uNWjHGGOOXJQhjjDF+WYIwxhjjlyUIY4wxflmCMMYY45clCGOMMX7VmG6uIrIL2Hwal2gI7K6icAKtOsUKFm+gVad4q1OsUDvibaWqjfztqDEJ4nSJyLyK+gKHmuoUK1i8gVad4q1OsYLFa1VMxhhj/LIEYYwxxi9LEEdMCHYAJ6E6xQoWb6BVp3irU6xQy+O1NghjjDF+WQnCGGOMX5YgjDHG+FXrE4SIDBWR1SKyTkTuDXY85YlICxGZLiIrRGS5iNztbX9QRDJFZJH3uCTYsZYRkU0istSLa563rYGIfC4ia73nxBCI8yyf+7dIRPaLyC9C6d6KyEsislNElvls83svxXnS+7e8RER6hUi8j4jIKi+mySJS39ueKiIFPvf53yESb4X//UXk/7z7u1pEfhQCsb7jE+cmEVnkba+ae6uqtfaBW8hoPdAGiAIWA52DHVe5GJsBvbzX9YA1QGfgQeCeYMdXQcybgIbltv0DuNd7fS/w92DH6effwnagVSjdW2AgbrndZSe6l8AlwCeAAP2AH0Ik3iFAhPf67z7xpvoeF0L31+9/f+//u8VAHaC199sRHsxYy+3/F/D7qry3tb0E0RdYp6obVPUQMBEYEeSYjqKq21R1gfc6F1gJJAc3qlMyAnjVe/0qcEXwQvHrQmC9qp7OaPwqp6rf4lZb9FXRvRwBvKbObKC+iDQ7I4F6/MWrqp+parH3djZuffqQUMH9rcgIYKKqHlTVjcA63G/IGXG8WEVEgGuBt6vyM2t7gkgGtvq8zyCEf3xFJBXoCfzgbbrTK7a/FApVNj4U+ExE5ovIeG9bE1Xd5r3eDjQJTmgVGs3R/3OF6r2Fiu9ldfj3/GNcKadMaxFZKCLfiMh5wQrKD3///UP5/p4H7FDVtT7bTvve1vYEUW2ISF3gPeAXqrofeA5oC/QAtuGKl6HiXFXtBQwDfiYiA313qisDh0z/ahGJAoYD//U2hfK9PUqo3cvjEZH7gWLgTW/TNqClqvYEfgW8JSLxwYrPR7X57+9jDEf/gVMl97a2J4hMoIXP+xRvW0gRkUhccnhTVd8HUNUdqlqiqqXAC5zBou6JqGqm97wTmIyLbUdZdYf3vDN4ER5jGLBAVXdAaN9bT0X3MmT/PYvIOOAy4HovqeFV1WR7r+fj6vQ7BC1Iz3H++4fk/RWRCOBK4J2ybVV1b2t7gpgLtBeR1t5fkaOBKUGO6She3eKLwEpVfdRnu2/d8khgWflzg0FE4kSkXtlrXAPlMtx9vck77Cbgw+BE6NdRf32F6r31UdG9nALc6PVm6gfk+FRFBY2IDAV+CwxX1Xyf7Y1EJNx73QZoD2wITpRHHOe//xRgtIjUEZHWuHjnnOn4/LgIWKWqGWUbquzenqkW+FB94Hp+rMFl2PuDHY+f+M7FVSEsARZ5j0uA14Gl3vYpQLNgx+rF2wbX02MxsLzsngJJwJfAWuALoEGwY/XiigOygQSfbSFzb3GJaxtQhKvzvqWie4nrvfSM9295KZAeIvGuw9Xdl/37/bd37FXev5FFwALg8hCJt8L//sD93v1dDQwLdqze9leA28odWyX31qbaMMYY41dtr2IyxhhTAUsQxhhj/LIEYYwxxi9LEMYYY/yyBGGMMcYvSxDGhAARGSQi/wt2HMb4sgRhjDHGL0sQxpwEERkrInO8OfafF5FwEckTkcfErdfxpYg08o7tISKzfdZBKFu3oZ2IfCEii0VkgYi09S5fV0QmeWsnvOmNojcmaCxBGFNJItIJGAUMUNUeQAlwPW409jxV7QJ8A/zBO+U14Heq2g03Mrds+5vAM6raHTgHNzoW3Ey9v8CtO9AGGBDgr2TMcUUEOwBjqpELgd7AXO+P+xjcRHmlHJko7Q3gfRFJAOqr6jfe9leB/3rzVCWr6mQAVS0E8K43R735dLyVwVKBGQH/VsZUwBKEMZUnwKuq+n9HbRT5f+WOO9X5aw76vC7B/v80QWZVTMZU3pfA1SLSGA6vDd0K9//R1d4x1wEzVDUH2OuzUMsNwDfqVgXMEJErvGvUEZHYM/kljKks+wvFmEpS1RUi8gButbww3KyaPwMOAH29fTtx7RTgpuL+t5cANgA3e9tvAJ4XkYe8a1xzBr+GMZVms7kac5pEJE9V6wY7DmOqmlUxGWOM8ctKEMYYY/yyEoQxxhi/LEEYY4zxyxKEMcYYvyxBGGOM8csShDHGGL/+P6++hcCU+Hm2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)\n",
    "siamese.compile(loss=utils.loss(1), optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "# siamese.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "siamese.summary()\n",
    "history = siamese.fit([x_train_1, x_train_2],\n",
    "                      labels_train,\n",
    "                      validation_data=([x_val_1, x_val_2], labels_val),\n",
    "                      batch_size=1,\n",
    "                      epochs=epochs,  # 175 for contrastive 100 for cross ent\n",
    "                      callbacks=[checkpointer, early_stopping, reduce_lr]\n",
    "                      )\n",
    "# print()\n",
    "# Plot the accuracy\n",
    "utils.plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")\n",
    "\n",
    "# Plot the constrastive loss\n",
    "utils.plt_metric(history=history.history, metric=\"loss\", title=\"Constrastive Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a897dfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 19s 2s/step - loss: 0.0901 - accuracy: 0.9470\n",
      "test loss, test acc: [0.09006506949663162, 0.9469696879386902]\n"
     ]
    }
   ],
   "source": [
    "results = siamese.evaluate([x_test_1, x_test_2], labels_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5020c970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate on validation data\n",
      "Accuracy: 0.946969696969697\n",
      "Precision: 0.9506944444444445\n",
      "Recall: 0.946969696969697\n",
      "ROC AUC: 0.9469696969696969\n",
      "F1: 0.9468599033816425\n"
     ]
    }
   ],
   "source": [
    "Y_pred = siamese.predict([x_test_1, x_test_2]).squeeze()\n",
    "# 返回的是TRUE或FALSE,没有标签数据怎么知道他被分到哪儿个类中？\n",
    "y_pred = Y_pred > 0.5\n",
    "# x1,和x2是否匹配：匹配1，不匹配0\n",
    "y_test = labels_test\n",
    "\n",
    "print(\"\\nEvaluate on validation data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bd41fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [1 if i else 0 for i in y_pred]\n",
    "pred_labels = []\n",
    "\n",
    "for i in range(0, len(y_pred)):\n",
    "    if y_pred[i] == 1:\n",
    "        pred_labels += [source_labels_test[i]]\n",
    "    else:\n",
    "        if source_labels_test[i] == 1:\n",
    "            pred_labels += [0.0]\n",
    "        else:\n",
    "            pred_labels += [1.0]\n",
    "a = x_test_1.tolist()\n",
    "df = pd.DataFrame({\"image\": a, \"label_{}\".format(teacher_id): pred_labels})\n",
    "df.to_excel(pre_results_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00ad007f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.9924242424242424\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "plt.show()\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7080bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
